2025-05-27 19:55:46,605 - INFO - allennlp.common.params - random_seed = 2021
2025-05-27 19:55:46,605 - INFO - allennlp.common.params - numpy_seed = 2021
2025-05-27 19:55:46,605 - INFO - allennlp.common.params - pytorch_seed = 2021
2025-05-27 19:55:46,606 - INFO - allennlp.common.checks - Pytorch version: 2.7.0+cu126
2025-05-27 19:55:46,606 - INFO - allennlp.common.params - type = default
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.type = reader_memory
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = bert-base-uncased
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 256
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2025-05-27 19:55:46,607 - INFO - allennlp.common.params - dataset_reader.tokenizer.verification_tokens = None
2025-05-27 19:55:51,141 - INFO - allennlp.common.params - dataset_reader.target = Security_Issue_Full
2025-05-27 19:55:51,141 - INFO - allennlp.common.params - dataset_reader.anchor_path = CWE_anchor_golden_project.json
2025-05-27 19:55:51,141 - INFO - allennlp.common.params - dataset_reader.sample_neg = 0.01
2025-05-27 19:55:51,141 - INFO - allennlp.common.params - dataset_reader.train_iter = 1
2025-05-27 19:55:51,141 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2025-05-27 19:55:51,141 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2025-05-27 19:55:51,142 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = bert-base-uncased
2025-05-27 19:55:51,142 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2025-05-27 19:55:51,142 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = None
2025-05-27 19:55:51,142 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2025-05-27 19:55:51,923 - INFO - allennlp.common.params - train_data_path = train_project.json
2025-05-27 19:55:51,923 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x73ef7f0731f0>
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - validation_dataset_reader = None
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - validation_data_path = validation_project.json
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - test_data_path = None
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - evaluate_on_test = False
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - batch_weight_key = 
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - data_loader.type = multiprocess
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - data_loader.batch_size = 8
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - data_loader.drop_last = False
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - data_loader.shuffle = False
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2025-05-27 19:55:51,932 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2025-05-27 19:55:51,933 - INFO - allennlp.common.params - data_loader.num_workers = 0
2025-05-27 19:55:51,933 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2025-05-27 19:55:51,933 - INFO - allennlp.common.params - data_loader.start_method = fork
2025-05-27 19:55:51,933 - INFO - allennlp.common.params - data_loader.cuda_device = None
2025-05-27 19:55:51,933 - INFO - allennlp.common.params - data_loader.quiet = False
2025-05-27 19:55:51,933 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x73ef8329ef80>
2025-05-27 19:55:51,933 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2025-05-27 20:04:43,910 - INFO - MemVul.reader_memory - {'pos': 3173, 'neg': 969570}
2025-05-27 20:04:44,305 - INFO - tqdm - loading instances: 1it [08:52, 532.37s/it]
2025-05-27 20:04:50,127 - INFO - MemVul.reader_memory - Dataset Count: Same : 50768 / Diff : 153296
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.type = multiprocess
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.batch_size = 8
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.drop_last = False
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.shuffle = False
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.batch_sampler = None
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.batches_per_epoch = None
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.num_workers = 0
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.max_instances_in_memory = None
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.start_method = fork
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.cuda_device = None
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.quiet = False
2025-05-27 20:04:50,136 - INFO - allennlp.common.params - validation_data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x73ef8329ef80>
2025-05-27 20:04:50,137 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2025-05-27 20:05:42,872 - INFO - MemVul.reader_memory - {'pos': 306, 'neg': 103273}
2025-05-27 20:05:42,872 - INFO - MemVul.reader_memory - Begin testing------
2025-05-27 20:05:42,872 - INFO - tqdm - loading instances: 1it [00:52, 52.74s/it]
2025-05-27 20:05:43,943 - INFO - MemVul.reader_memory - Test sample num is 103579
2025-05-27 20:05:43,945 - INFO - allennlp.common.params - type = from_instances
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - min_count = None
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - max_vocab_size = None
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - pretrained_files = None
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - only_include_pretrained_words = False
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - tokens_to_add = None
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2025-05-27 20:05:43,946 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2025-05-27 20:05:43,946 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2025-05-27 20:05:43,946 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2025-05-27 20:05:48,148 - INFO - allennlp.common.params - model.type = model_memory
2025-05-27 20:05:48,148 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2025-05-27 20:05:48,148 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = bert-base-uncased
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.eval_mode = False
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.reinit_modules = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.load_weights = True
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2025-05-27 20:05:48,149 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2025-05-27 20:05:49,449 - INFO - allennlp.common.params - model.PTM = bert-base-uncased
2025-05-27 20:05:49,449 - INFO - allennlp.common.params - model.dropout = 0.1
2025-05-27 20:05:49,449 - INFO - allennlp.common.params - model.label_namespace = labels
2025-05-27 20:05:49,450 - INFO - allennlp.common.params - model.device = cuda:0
2025-05-27 20:05:49,450 - INFO - allennlp.common.params - model.use_header = True
2025-05-27 20:05:49,450 - INFO - allennlp.common.params - model.temperature = 0.1
2025-05-27 20:05:49,450 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x73ef7dc5e170>
2025-05-27 20:05:49,450 - INFO - allennlp.common.params - model.regularizer = None
2025-05-27 20:05:49,452 - INFO - allennlp.nn.initializers - Initializing parameters
2025-05-27 20:05:49,453 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2025-05-27 20:05:49,453 - INFO - allennlp.nn.initializers -    _bert_pooler.pooler.dense.bias
2025-05-27 20:05:49,453 - INFO - allennlp.nn.initializers -    _bert_pooler.pooler.dense.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _projector.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _projector_single._linear_layers.0.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _projector_single._linear_layers.0.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2025-05-27 20:05:49,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2025-05-27 20:05:49,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2025-05-27 20:05:49,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2025-05-27 20:05:49,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2025-05-27 20:05:49,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2025-05-27 20:05:49,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2025-05-27 20:05:49,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2025-05-27 20:05:56,922 - INFO - allennlp.common.params - trainer.type = custom_gradient_descent
2025-05-27 20:05:56,923 - INFO - allennlp.common.params - trainer.patience = 10
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.validation_metric = +s_f1-score
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.num_epochs = 1
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.cuda_device = 0
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.grad_norm = None
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.grad_clipping = None
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.distributed = False
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.world_size = 1
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 2
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.use_amp = False
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.no_grad = None
2025-05-27 20:05:56,932 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2025-05-27 20:05:56,933 - INFO - allennlp.common.params - trainer.moving_average = None
2025-05-27 20:05:56,933 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x73ef7dc5ded0>
2025-05-27 20:05:56,933 - INFO - allennlp.common.params - trainer.callbacks = None
2025-05-27 20:05:56,933 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2025-05-27 20:05:56,933 - INFO - allennlp.common.params - trainer.run_sanity_checks = True
2025-05-27 20:05:57,172 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw
2025-05-27 20:05:57,172 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0001
2025-05-27 20:05:57,172 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.999]
2025-05-27 20:05:57,172 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2025-05-27 20:05:57,172 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2025-05-27 20:05:57,172 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True
2025-05-27 20:05:57,173 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2025-05-27 20:05:57,173 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight'], {'lr': 2e-05, 'requires_grad': True}
2025-05-27 20:05:57,174 - INFO - allennlp.training.optimizers - Group 1: ['_bert_pooler.pooler.dense.bias', '_bert_pooler.pooler.dense.weight'], {'lr': 5e-05, 'requires_grad': True}
2025-05-27 20:05:57,174 - INFO - allennlp.training.optimizers - Group 2: ['_projector_single._linear_layers.0.bias', '_projector_single._linear_layers.0.weight', '_projector.weight'], {}
2025-05-27 20:05:57,174 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110469632
2025-05-27 20:05:57,759 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2025-05-27 20:05:57,759 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2025-05-27 20:05:57,760 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2025-05-27 20:05:57,761 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2025-05-27 20:05:57,762 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _bert_pooler.pooler.dense.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _bert_pooler.pooler.dense.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _projector_single._linear_layers.0.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _projector_single._linear_layers.0.bias
2025-05-27 20:05:57,763 - INFO - allennlp.common.util - _projector.weight
2025-05-27 20:05:57,763 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = linear_with_warmup
2025-05-27 20:05:57,763 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 10000
2025-05-27 20:05:57,763 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2025-05-27 20:05:57,763 - INFO - allennlp.common.params - type = default
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - save_completed_epochs = True
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - save_every_num_seconds = None
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - save_every_num_batches = None
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - keep_most_recent_by_count = 2
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - keep_most_recent_by_age = None
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.0.type = reset_dataloader
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.type = custom_validation
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.anchor_path = CWE_anchor_golden_project.json
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.type = reader_memory
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.tokenizer.type = pretrained_transformer
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.tokenizer.model_name = bert-base-uncased
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.tokenizer.add_special_tokens = True
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.tokenizer.max_length = 512
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.tokenizer.tokenizer_kwargs = None
2025-05-27 20:05:57,764 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.tokenizer.verification_tokens = None
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.same_diff_ratio = None
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.target = Security_Issue_Full
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.anchor_path = CWE_anchor_golden_project.json
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.sample_neg = None
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.train_iter = None
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.token_indexers.tokens.type = pretrained_transformer
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.token_indexers.tokens.token_min_padding_length = 0
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.token_indexers.tokens.model_name = bert-base-uncased
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.token_indexers.tokens.namespace = tags
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.token_indexers.tokens.max_length = None
2025-05-27 20:05:57,765 - INFO - allennlp.common.params - trainer.custom_callbacks.1.data_reader.token_indexers.tokens.tokenizer_kwargs = None
2025-05-27 20:05:58,286 - INFO - MemVul.reader_memory - {'pos': 131, 'neg': None}
2025-05-27 20:05:58,286 - INFO - MemVul.reader_memory - Begin loading golden instances------
2025-05-27 20:05:58,289 - INFO - MemVul.reader_memory - Num of golden instances is 131
2025-05-27 20:05:58,290 - INFO - MemVul.custom_trainer - Beginning training.
2025-05-27 20:05:58,290 - INFO - MemVul.custom_trainer - Epoch 0/0
2025-05-27 20:05:58,290 - INFO - MemVul.custom_trainer - Worker 0 memory usage: 35G
2025-05-27 20:05:58,290 - INFO - MemVul.custom_trainer - GPU 0 memory usage: 423M
2025-05-27 20:05:58,291 - INFO - MemVul.custom_trainer - Training
2025-05-27 20:05:58,291 - INFO - tqdm - 0%|          | 0/12754 [00:00<?, ?it/s]
2025-05-27 20:05:59,353 - INFO - allennlp.training.callbacks.console_logger - Batch inputs
2025-05-27 20:05:59,353 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample1/tokens/token_ids (Shape: 8 x 77)
tensor([[ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        ...,
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102]], device='cuda:0')
2025-05-27 20:05:59,356 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample1/tokens/mask (Shape: 8 x 77)
tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0')
2025-05-27 20:05:59,357 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample1/tokens/type_ids (Shape: 8 x 77)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')
2025-05-27 20:05:59,359 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample2/tokens/token_ids (Shape: 8 x 256)
tensor([[  101, 24156,  8699,  ...,  2008, 19933,   102],
        [  101, 27280, 11826,  ...,  2038,  1037,   102],
        [  101,  2041,  1011,  ...,  1012,  3191,   102],
        ...,
        [  101,  3622,  5227,  ...,  1999, 25718,   102],
        [  101, 24156, 27280,  ...,  4767,  1012,   102],
        [  101, 27280, 11826,  ...,  2038,  1037,   102]], device='cuda:0')
2025-05-27 20:05:59,360 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample2/tokens/mask (Shape: 8 x 256)
tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0')
2025-05-27 20:05:59,362 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample2/tokens/type_ids (Shape: 8 x 256)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')
2025-05-27 20:05:59,363 - INFO - allennlp.training.callbacks.console_logger - batch_input/label (Shape: 8)
tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')
2025-05-27 20:05:59,364 - INFO - allennlp.training.callbacks.console_logger - Field : "batch_input/metadata" : (Length 8 of type "<class 'dict'>")
2025-05-27 20:05:59,364 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample1/tokens/token_ids (Shape: 8 x 77)
tensor([[ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        ...,
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102],
        [ 101, 2129, 2000,  ..., 4372, 2615,  102]], device='cuda:0')
2025-05-27 20:05:59,365 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample1/tokens/mask (Shape: 8 x 77)
tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0')
2025-05-27 20:05:59,367 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample1/tokens/type_ids (Shape: 8 x 77)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')
2025-05-27 20:05:59,368 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample2/tokens/token_ids (Shape: 8 x 256)
tensor([[  101,  8241,  1011,  ...,  4851,  2005,   102],
        [  101, 24156,  8699,  ...,  2008,  2071,   102],
        [  101,  4394, 27280,  ...,  2515,  2025,   102],
        ...,
        [  101, 17698,  6100,  ...,  1997,  3036,   102],
        [  101, 16542,  3229,  ...,  7692,  8381,   102],
        [  101,  4895,  8663,  ...,  3677,  4082,   102]], device='cuda:0')
2025-05-27 20:05:59,370 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample2/tokens/mask (Shape: 8 x 256)
tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0')
2025-05-27 20:05:59,372 - INFO - allennlp.training.callbacks.console_logger - batch_input/sample2/tokens/type_ids (Shape: 8 x 256)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')
2025-05-27 20:05:59,373 - INFO - allennlp.training.callbacks.console_logger - batch_input/label (Shape: 8)
tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')
2025-05-27 20:05:59,373 - INFO - allennlp.training.callbacks.console_logger - Field : "batch_input/metadata" : (Length 8 of type "<class 'dict'>")
2025-05-27 20:06:08,873 - INFO - tqdm - accuracy: 0.1384, precision: 0.0199, recall: 0.1384, f1-score: 0.0347, diff_precision: 0.0000, diff_recall: 0.0000, diff_f1-score: 0.0000, same_precision: 0.1390, same_recall: 0.9688, same_f1-score: 0.2431, batch_loss: 2.2770, loss: 2.2121 ||:   0%|          | 14/12754 [00:10<2:48:52,  1.26it/s]
2025-05-27 20:06:19,165 - INFO - tqdm - accuracy: 0.1763, precision: 0.0316, recall: 0.1763, f1-score: 0.0535, diff_precision: 0.0000, diff_recall: 0.0000, diff_f1-score: 0.0000, same_precision: 0.1767, same_recall: 0.9875, same_f1-score: 0.2998, batch_loss: 2.8790, loss: 2.1963 ||:   0%|          | 28/12754 [00:20<2:27:41,  1.44it/s]
2025-05-27 20:06:29,877 - INFO - tqdm - accuracy: 0.1818, precision: 0.4418, recall: 0.1818, f1-score: 0.0610, diff_precision: 0.5000, diff_recall: 0.0035, diff_f1-score: 0.0069, same_precision: 0.1800, same_recall: 0.9844, same_f1-score: 0.3043, batch_loss: 0.2396, loss: 2.1939 ||:   0%|          | 44/12754 [00:31<2:41:16,  1.31it/s]
2025-05-27 20:06:39,925 - INFO - tqdm - accuracy: 0.2034, precision: 0.4390, recall: 0.2034, f1-score: 0.0780, diff_precision: 0.5000, diff_recall: 0.0066, diff_f1-score: 0.0131, same_precision: 0.2002, same_recall: 0.9740, same_f1-score: 0.3321, batch_loss: 2.5882, loss: 2.0847 ||:   0%|          | 59/12754 [00:41<2:20:09,  1.51it/s]
2025-05-27 20:06:50,221 - INFO - tqdm - accuracy: 0.2166, precision: 0.3755, recall: 0.2166, f1-score: 0.0899, diff_precision: 0.4211, diff_recall: 0.0088, diff_f1-score: 0.0172, same_precision: 0.2132, same_recall: 0.9570, same_f1-score: 0.3488, batch_loss: 0.3598, loss: 2.0076 ||:   1%|          | 73/12754 [00:51<2:51:27,  1.23it/s]
2025-05-27 20:07:00,520 - INFO - tqdm - accuracy: 0.2102, precision: 0.5270, recall: 0.2102, f1-score: 0.0978, diff_precision: 0.6111, diff_recall: 0.0196, diff_f1-score: 0.0381, same_precision: 0.1997, same_recall: 0.9514, same_f1-score: 0.3301, batch_loss: 1.8841, loss: 1.9427 ||:   1%|          | 88/12754 [01:02<2:27:16,  1.43it/s]
2025-05-27 20:07:10,719 - INFO - tqdm - accuracy: 0.2392, precision: 0.5088, recall: 0.2392, f1-score: 0.1328, diff_precision: 0.5946, diff_recall: 0.0344, diff_f1-score: 0.0650, same_precision: 0.2226, same_recall: 0.9219, same_f1-score: 0.3587, batch_loss: 0.3271, loss: 1.8316 ||:   1%|          | 104/12754 [01:12<1:57:52,  1.79it/s]
2025-05-27 20:07:20,967 - INFO - tqdm - accuracy: 0.2601, precision: 0.5591, recall: 0.2601, f1-score: 0.1722, diff_precision: 0.6617, diff_recall: 0.0611, diff_f1-score: 0.1119, same_precision: 0.2296, same_recall: 0.8996, same_f1-score: 0.3659, batch_loss: 1.1339, loss: 1.7354 ||:   1%|          | 118/12754 [01:22<2:25:46,  1.44it/s]
2025-05-27 20:07:31,018 - INFO - tqdm - accuracy: 0.2817, precision: 0.5494, recall: 0.2817, f1-score: 0.2123, diff_precision: 0.6530, diff_recall: 0.0903, diff_f1-score: 0.1586, same_precision: 0.2388, same_recall: 0.8561, same_f1-score: 0.3734, batch_loss: 0.8057, loss: 1.6422 ||:   1%|1         | 132/12754 [01:32<2:54:24,  1.21it/s]
2025-05-27 20:07:41,543 - INFO - tqdm - accuracy: 0.3091, precision: 0.5982, recall: 0.3091, f1-score: 0.2687, diff_precision: 0.7151, diff_recall: 0.1413, diff_f1-score: 0.2360, same_precision: 0.2379, same_recall: 0.8264, same_f1-score: 0.3694, batch_loss: 0.5319, loss: 1.5508 ||:   1%|1         | 147/12754 [01:43<2:30:51,  1.39it/s]
2025-05-27 20:07:52,053 - INFO - tqdm - accuracy: 0.3387, precision: 0.6429, recall: 0.3387, f1-score: 0.3236, diff_precision: 0.7679, diff_recall: 0.1951, diff_f1-score: 0.3111, same_precision: 0.2352, same_recall: 0.8076, same_f1-score: 0.3642, batch_loss: 0.5315, loss: 1.4702 ||:   1%|1         | 162/12754 [01:53<2:16:01,  1.54it/s]
2025-05-27 20:08:02,829 - INFO - tqdm - accuracy: 0.3658, precision: 0.6383, recall: 0.3658, f1-score: 0.3681, diff_precision: 0.7630, diff_recall: 0.2444, diff_f1-score: 0.3703, same_precision: 0.2374, same_recall: 0.7560, same_f1-score: 0.3613, batch_loss: 0.3929, loss: 1.3999 ||:   1%|1         | 177/12754 [02:04<2:42:44,  1.29it/s]
2025-05-27 20:08:13,168 - INFO - tqdm - accuracy: 0.3949, precision: 0.6501, recall: 0.3949, f1-score: 0.4111, diff_precision: 0.7760, diff_recall: 0.2946, diff_f1-score: 0.4271, same_precision: 0.2386, same_recall: 0.7222, same_f1-score: 0.3587, batch_loss: 0.2846, loss: 1.3345 ||:   2%|1         | 192/12754 [02:14<2:31:27,  1.38it/s]
2025-05-27 20:08:23,778 - INFO - tqdm - accuracy: 0.4227, precision: 0.6584, recall: 0.4227, f1-score: 0.4488, diff_precision: 0.7847, diff_recall: 0.3424, diff_f1-score: 0.4767, same_precision: 0.2402, same_recall: 0.6888, same_f1-score: 0.3562, batch_loss: 0.2807, loss: 1.2751 ||:   2%|1         | 207/12754 [02:25<2:30:03,  1.39it/s]
2025-05-27 20:08:34,440 - INFO - tqdm - accuracy: 0.4431, precision: 0.6536, recall: 0.4431, f1-score: 0.4742, diff_precision: 0.7794, diff_recall: 0.3805, diff_f1-score: 0.5114, same_precision: 0.2424, same_recall: 0.6478, same_f1-score: 0.3527, batch_loss: 0.2256, loss: 1.2309 ||:   2%|1         | 222/12754 [02:36<2:36:21,  1.34it/s]
2025-05-27 20:08:45,158 - INFO - tqdm - accuracy: 0.4668, precision: 0.6620, recall: 0.4668, f1-score: 0.5016, diff_precision: 0.7878, diff_recall: 0.4183, diff_f1-score: 0.5464, same_precision: 0.2458, same_recall: 0.6273, same_f1-score: 0.3532, batch_loss: 1.8627, loss: 1.1841 ||:   2%|1         | 237/12754 [02:46<2:36:26,  1.33it/s]
2025-05-27 20:08:55,228 - INFO - tqdm - accuracy: 0.4851, precision: 0.6650, recall: 0.4851, f1-score: 0.5218, diff_precision: 0.7904, diff_recall: 0.4495, diff_f1-score: 0.5731, same_precision: 0.2478, same_recall: 0.6034, same_f1-score: 0.3513, batch_loss: 0.2704, loss: 1.1464 ||:   2%|1         | 251/12754 [02:56<2:29:05,  1.40it/s]
2025-05-27 20:09:05,480 - INFO - tqdm - accuracy: 0.4986, precision: 0.6584, recall: 0.4986, f1-score: 0.5340, diff_precision: 0.7839, diff_recall: 0.4725, diff_f1-score: 0.5896, same_precision: 0.2561, same_recall: 0.5823, same_f1-score: 0.3558, batch_loss: 0.7880, loss: 1.1133 ||:   2%|2         | 265/12754 [03:07<2:12:31,  1.57it/s]
2025-05-27 20:09:15,613 - INFO - tqdm - accuracy: 0.5116, precision: 0.6582, recall: 0.5116, f1-score: 0.5464, diff_precision: 0.7834, diff_recall: 0.4938, diff_f1-score: 0.6058, same_precision: 0.2618, same_recall: 0.5681, same_f1-score: 0.3584, batch_loss: 0.9986, loss: 1.0832 ||:   2%|2         | 279/12754 [03:17<2:38:12,  1.31it/s]
2025-05-27 20:09:25,808 - INFO - tqdm - accuracy: 0.5306, precision: 0.6755, recall: 0.5306, f1-score: 0.5671, diff_precision: 0.7998, diff_recall: 0.5194, diff_f1-score: 0.6298, same_precision: 0.2623, same_recall: 0.5680, same_f1-score: 0.3589, batch_loss: 0.2300, loss: 1.0440 ||:   2%|2         | 294/12754 [03:27<2:37:43,  1.32it/s]
2025-05-27 20:09:36,064 - INFO - tqdm - accuracy: 0.5502, precision: 0.6906, recall: 0.5502, f1-score: 0.5877, diff_precision: 0.8134, diff_recall: 0.5461, diff_f1-score: 0.6535, same_precision: 0.2633, same_recall: 0.5643, same_f1-score: 0.3591, batch_loss: 0.1712, loss: 1.0043 ||:   2%|2         | 309/12754 [03:37<2:09:50,  1.60it/s]
2025-05-27 20:09:46,112 - INFO - tqdm - accuracy: 0.5596, precision: 0.6869, recall: 0.5596, f1-score: 0.5955, diff_precision: 0.8094, diff_recall: 0.5638, diff_f1-score: 0.6646, same_precision: 0.2674, same_recall: 0.5454, same_f1-score: 0.3589, batch_loss: 0.1223, loss: 0.9838 ||:   3%|2         | 323/12754 [03:47<2:42:45,  1.27it/s]
2025-05-27 20:09:56,176 - INFO - tqdm - accuracy: 0.5734, precision: 0.6944, recall: 0.5734, f1-score: 0.6090, diff_precision: 0.8157, diff_recall: 0.5837, diff_f1-score: 0.6804, same_precision: 0.2691, same_recall: 0.5375, same_f1-score: 0.3586, batch_loss: 0.1066, loss: 0.9534 ||:   3%|2         | 338/12754 [03:57<2:18:35,  1.49it/s]
2025-05-27 20:10:06,595 - INFO - tqdm - accuracy: 0.5856, precision: 0.6973, recall: 0.5856, f1-score: 0.6194, diff_precision: 0.8179, diff_recall: 0.6002, diff_f1-score: 0.6924, same_precision: 0.2776, same_recall: 0.5348, same_f1-score: 0.3655, batch_loss: 0.0579, loss: 0.9270 ||:   3%|2         | 354/12754 [04:08<2:27:54,  1.40it/s]
2025-05-27 20:10:16,702 - INFO - tqdm - accuracy: 0.5964, precision: 0.6997, recall: 0.5964, f1-score: 0.6283, diff_precision: 0.8196, diff_recall: 0.6145, diff_f1-score: 0.7024, same_precision: 0.2867, same_recall: 0.5339, same_f1-score: 0.3731, batch_loss: 0.1419, loss: 0.9045 ||:   3%|2         | 369/12754 [04:18<2:22:50,  1.45it/s]
2025-05-27 20:10:26,917 - INFO - tqdm - accuracy: 0.6031, precision: 0.6977, recall: 0.6031, f1-score: 0.6328, diff_precision: 0.8172, diff_recall: 0.6244, diff_f1-score: 0.7079, same_precision: 0.2970, same_recall: 0.5320, same_f1-score: 0.3812, batch_loss: 0.2064, loss: 0.8892 ||:   3%|3         | 383/12754 [04:28<2:15:46,  1.52it/s]
2025-05-27 20:10:36,991 - INFO - tqdm - accuracy: 0.6148, precision: 0.7067, recall: 0.6148, f1-score: 0.6440, diff_precision: 0.8249, diff_recall: 0.6376, diff_f1-score: 0.7192, same_precision: 0.3021, same_recall: 0.5368, same_f1-score: 0.3866, batch_loss: 0.1255, loss: 0.8662 ||:   3%|3         | 398/12754 [04:38<2:10:27,  1.58it/s]
2025-05-27 20:10:47,351 - INFO - tqdm - accuracy: 0.6236, precision: 0.7117, recall: 0.6236, f1-score: 0.6522, diff_precision: 0.8288, diff_recall: 0.6496, diff_f1-score: 0.7283, same_precision: 0.3044, same_recall: 0.5333, same_f1-score: 0.3876, batch_loss: 0.0654, loss: 0.8470 ||:   3%|3         | 412/12754 [04:49<2:52:21,  1.19it/s]
2025-05-27 20:10:57,774 - INFO - tqdm - accuracy: 0.6330, precision: 0.7153, recall: 0.6330, f1-score: 0.6601, diff_precision: 0.8314, diff_recall: 0.6610, diff_f1-score: 0.7364, same_precision: 0.3139, same_recall: 0.5365, same_f1-score: 0.3961, batch_loss: 0.1863, loss: 0.8267 ||:   3%|3         | 428/12754 [04:59<2:12:52,  1.55it/s]
2025-05-27 20:11:08,118 - INFO - tqdm - accuracy: 0.6395, precision: 0.7144, recall: 0.6395, f1-score: 0.6643, diff_precision: 0.8298, diff_recall: 0.6692, diff_f1-score: 0.7409, same_precision: 0.3274, same_recall: 0.5398, same_f1-score: 0.4076, batch_loss: 0.3017, loss: 0.8111 ||:   3%|3         | 444/12754 [05:09<2:03:01,  1.67it/s]
2025-05-27 20:11:18,632 - INFO - tqdm - accuracy: 0.6482, precision: 0.7220, recall: 0.6482, f1-score: 0.6730, diff_precision: 0.8362, diff_recall: 0.6792, diff_f1-score: 0.7496, same_precision: 0.3287, same_recall: 0.5413, same_f1-score: 0.4090, batch_loss: 0.4139, loss: 0.7923 ||:   4%|3         | 458/12754 [05:20<2:19:59,  1.46it/s]
2025-05-27 20:11:29,206 - INFO - tqdm - accuracy: 0.6544, precision: 0.7229, recall: 0.6544, f1-score: 0.6774, diff_precision: 0.8362, diff_recall: 0.6854, diff_f1-score: 0.7534, same_precision: 0.3432, same_recall: 0.5505, same_f1-score: 0.4228, batch_loss: 2.1473, loss: 0.7821 ||:   4%|3         | 474/12754 [05:30<2:18:14,  1.48it/s]
2025-05-27 20:11:39,416 - INFO - tqdm - accuracy: 0.6631, precision: 0.7291, recall: 0.6631, f1-score: 0.6853, diff_precision: 0.8412, diff_recall: 0.6940, diff_f1-score: 0.7605, same_precision: 0.3518, same_recall: 0.5592, same_f1-score: 0.4319, batch_loss: 0.3852, loss: 0.7648 ||:   4%|3         | 489/12754 [05:41<2:07:40,  1.60it/s]
2025-05-27 20:11:50,146 - INFO - tqdm - accuracy: 0.6684, precision: 0.7287, recall: 0.6684, f1-score: 0.6886, diff_precision: 0.8399, diff_recall: 0.6992, diff_f1-score: 0.7631, same_precision: 0.3689, same_recall: 0.5688, same_f1-score: 0.4475, batch_loss: 0.1499, loss: 0.7550 ||:   4%|3         | 504/12754 [05:51<2:40:28,  1.27it/s]
2025-05-27 20:12:00,155 - INFO - tqdm - accuracy: 0.6733, precision: 0.7323, recall: 0.6733, f1-score: 0.6931, diff_precision: 0.8428, diff_recall: 0.7039, diff_f1-score: 0.7671, same_precision: 0.3738, same_recall: 0.5738, same_f1-score: 0.4527, batch_loss: 0.2588, loss: 0.7451 ||:   4%|4         | 518/12754 [06:01<2:20:50,  1.45it/s]
2025-05-27 20:12:10,573 - INFO - tqdm - accuracy: 0.6782, precision: 0.7329, recall: 0.6782, f1-score: 0.6966, diff_precision: 0.8424, diff_recall: 0.7093, diff_f1-score: 0.7701, same_precision: 0.3867, same_recall: 0.5801, same_f1-score: 0.4641, batch_loss: 0.7735, loss: 0.7362 ||:   4%|4         | 533/12754 [06:12<2:20:09,  1.45it/s]
2025-05-27 20:12:20,911 - INFO - tqdm - accuracy: 0.6845, precision: 0.7377, recall: 0.6845, f1-score: 0.7024, diff_precision: 0.8461, diff_recall: 0.7153, diff_f1-score: 0.7752, same_precision: 0.3936, same_recall: 0.5868, same_f1-score: 0.4712, batch_loss: 0.1634, loss: 0.7233 ||:   4%|4         | 547/12754 [06:22<2:25:24,  1.40it/s]
2025-05-27 20:12:31,235 - INFO - tqdm - accuracy: 0.6915, precision: 0.7423, recall: 0.6915, f1-score: 0.7086, diff_precision: 0.8493, diff_recall: 0.7220, diff_f1-score: 0.7805, same_precision: 0.4036, same_recall: 0.5949, same_f1-score: 0.4809, batch_loss: 0.0343, loss: 0.7096 ||:   4%|4         | 562/12754 [06:32<2:21:38,  1.43it/s]
2025-05-27 20:12:41,503 - INFO - tqdm - accuracy: 0.6977, precision: 0.7466, recall: 0.6977, f1-score: 0.7142, diff_precision: 0.8525, diff_recall: 0.7285, diff_f1-score: 0.7856, same_precision: 0.4105, same_recall: 0.6001, same_f1-score: 0.4875, batch_loss: 0.0681, loss: 0.6990 ||:   5%|4         | 576/12754 [06:43<2:26:35,  1.38it/s]
2025-05-27 20:12:51,696 - INFO - tqdm - accuracy: 0.7031, precision: 0.7501, recall: 0.7031, f1-score: 0.7190, diff_precision: 0.8550, diff_recall: 0.7344, diff_f1-score: 0.7901, same_precision: 0.4163, same_recall: 0.6033, same_f1-score: 0.4927, batch_loss: 0.1596, loss: 0.6889 ||:   5%|4         | 590/12754 [06:53<2:31:10,  1.34it/s]
2025-05-27 20:13:02,202 - INFO - tqdm - accuracy: 0.7083, precision: 0.7542, recall: 0.7083, f1-score: 0.7240, diff_precision: 0.8580, diff_recall: 0.7404, diff_f1-score: 0.7948, same_precision: 0.4195, same_recall: 0.6049, same_f1-score: 0.4954, batch_loss: 0.0414, loss: 0.6792 ||:   5%|4         | 604/12754 [07:03<2:30:15,  1.35it/s]
2025-05-27 20:13:12,722 - INFO - tqdm - accuracy: 0.7122, precision: 0.7546, recall: 0.7122, f1-score: 0.7267, diff_precision: 0.8572, diff_recall: 0.7441, diff_f1-score: 0.7967, same_precision: 0.4336, same_recall: 0.6125, same_f1-score: 0.5078, batch_loss: 0.2240, loss: 0.6710 ||:   5%|4         | 619/12754 [07:14<2:07:23,  1.59it/s]
2025-05-27 20:13:23,212 - INFO - tqdm - accuracy: 0.7162, precision: 0.7566, recall: 0.7162, f1-score: 0.7300, diff_precision: 0.8582, diff_recall: 0.7479, diff_f1-score: 0.7993, same_precision: 0.4424, same_recall: 0.6181, same_f1-score: 0.5157, batch_loss: 0.0531, loss: 0.6639 ||:   5%|4         | 634/12754 [07:24<2:27:33,  1.37it/s]
2025-05-27 20:13:33,631 - INFO - tqdm - accuracy: 0.7205, precision: 0.7597, recall: 0.7205, f1-score: 0.7339, diff_precision: 0.8604, diff_recall: 0.7524, diff_f1-score: 0.8028, same_precision: 0.4473, same_recall: 0.6214, same_f1-score: 0.5202, batch_loss: 0.0313, loss: 0.6551 ||:   5%|5         | 648/12754 [07:35<2:18:55,  1.45it/s]
2025-05-27 20:13:43,638 - INFO - tqdm - accuracy: 0.7248, precision: 0.7637, recall: 0.7248, f1-score: 0.7382, diff_precision: 0.8636, diff_recall: 0.7573, diff_f1-score: 0.8070, same_precision: 0.4482, same_recall: 0.6222, same_f1-score: 0.5211, batch_loss: 0.0471, loss: 0.6457 ||:   5%|5         | 661/12754 [07:45<2:49:54,  1.19it/s]
2025-05-27 20:13:54,081 - INFO - tqdm - accuracy: 0.7300, precision: 0.7673, recall: 0.7300, f1-score: 0.7429, diff_precision: 0.8660, diff_recall: 0.7631, diff_f1-score: 0.8113, same_precision: 0.4534, same_recall: 0.6246, same_f1-score: 0.5254, batch_loss: 0.5335, loss: 0.6356 ||:   5%|5         | 677/12754 [07:55<2:00:19,  1.67it/s]
2025-05-27 20:14:04,322 - INFO - tqdm - accuracy: 0.7339, precision: 0.7690, recall: 0.7339, f1-score: 0.7461, diff_precision: 0.8665, diff_recall: 0.7667, diff_f1-score: 0.8136, same_precision: 0.4647, same_recall: 0.6317, same_f1-score: 0.5355, batch_loss: 0.5542, loss: 0.6278 ||:   5%|5         | 692/12754 [08:06<2:09:12,  1.56it/s]
2025-05-27 20:14:15,059 - INFO - tqdm - accuracy: 0.7385, precision: 0.7720, recall: 0.7385, f1-score: 0.7501, diff_precision: 0.8684, diff_recall: 0.7706, diff_f1-score: 0.8166, same_precision: 0.4745, same_recall: 0.6395, same_f1-score: 0.5448, batch_loss: 0.0411, loss: 0.6193 ||:   6%|5         | 707/12754 [08:16<2:27:39,  1.36it/s]
2025-05-27 20:14:25,572 - INFO - tqdm - accuracy: 0.7424, precision: 0.7751, recall: 0.7424, f1-score: 0.7537, diff_precision: 0.8706, diff_recall: 0.7745, diff_f1-score: 0.8197, same_precision: 0.4788, same_recall: 0.6428, same_f1-score: 0.5488, batch_loss: 0.0750, loss: 0.6116 ||:   6%|5         | 722/12754 [08:27<2:19:44,  1.44it/s]
2025-05-27 20:14:35,790 - INFO - tqdm - accuracy: 0.7468, precision: 0.7788, recall: 0.7468, f1-score: 0.7579, diff_precision: 0.8733, diff_recall: 0.7792, diff_f1-score: 0.8236, same_precision: 0.4819, same_recall: 0.6450, same_f1-score: 0.5517, batch_loss: 0.4944, loss: 0.6018 ||:   6%|5         | 737/12754 [08:37<2:06:04,  1.59it/s]
2025-05-27 20:14:46,688 - INFO - tqdm - accuracy: 0.7517, precision: 0.7834, recall: 0.7517, f1-score: 0.7628, diff_precision: 0.8770, diff_recall: 0.7847, diff_f1-score: 0.8283, same_precision: 0.4816, same_recall: 0.6450, same_f1-score: 0.5515, batch_loss: 0.2825, loss: 0.5907 ||:   6%|5         | 752/12754 [08:48<2:34:49,  1.29it/s]
2025-05-27 20:14:57,306 - INFO - tqdm - accuracy: 0.7545, precision: 0.7846, recall: 0.7545, f1-score: 0.7651, diff_precision: 0.8772, diff_recall: 0.7885, diff_f1-score: 0.8305, same_precision: 0.4869, same_recall: 0.6453, same_f1-score: 0.5550, batch_loss: 0.0157, loss: 0.5854 ||:   6%|6         | 767/12754 [08:59<2:14:29,  1.49it/s]
2025-05-27 20:15:07,456 - INFO - tqdm - accuracy: 0.7582, precision: 0.7873, recall: 0.7582, f1-score: 0.7685, diff_precision: 0.8789, diff_recall: 0.7924, diff_f1-score: 0.8334, same_precision: 0.4915, same_recall: 0.6476, same_f1-score: 0.5589, batch_loss: 0.1034, loss: 0.5782 ||:   6%|6         | 782/12754 [09:09<2:21:28,  1.41it/s]
2025-05-27 20:15:18,281 - INFO - tqdm - accuracy: 0.7604, precision: 0.7881, recall: 0.7604, f1-score: 0.7703, diff_precision: 0.8789, diff_recall: 0.7949, diff_f1-score: 0.8348, same_precision: 0.4986, same_recall: 0.6507, same_f1-score: 0.5646, batch_loss: 0.7703, loss: 0.5740 ||:   6%|6         | 796/12754 [09:19<2:36:07,  1.28it/s]
2025-05-27 20:15:28,290 - INFO - tqdm - accuracy: 0.7630, precision: 0.7894, recall: 0.7630, f1-score: 0.7724, diff_precision: 0.8792, diff_recall: 0.7969, diff_f1-score: 0.8360, same_precision: 0.5080, same_recall: 0.6569, same_f1-score: 0.5729, batch_loss: 0.5627, loss: 0.5696 ||:   6%|6         | 810/12754 [09:29<2:25:04,  1.37it/s]
2025-05-27 20:15:38,401 - INFO - tqdm - accuracy: 0.7663, precision: 0.7915, recall: 0.7663, f1-score: 0.7752, diff_precision: 0.8803, diff_recall: 0.7993, diff_f1-score: 0.8378, same_precision: 0.5172, same_recall: 0.6643, same_f1-score: 0.5816, batch_loss: 0.1771, loss: 0.5633 ||:   6%|6         | 826/12754 [09:40<2:11:05,  1.52it/s]
2025-05-27 20:15:48,695 - INFO - tqdm - accuracy: 0.7686, precision: 0.7927, recall: 0.7686, f1-score: 0.7771, diff_precision: 0.8807, diff_recall: 0.8017, diff_f1-score: 0.8393, same_precision: 0.5234, same_recall: 0.6673, same_f1-score: 0.5867, batch_loss: 0.5661, loss: 0.5586 ||:   7%|6         | 841/12754 [09:50<2:02:39,  1.62it/s]
2025-05-27 20:15:59,376 - INFO - tqdm - accuracy: 0.7711, precision: 0.7943, recall: 0.7711, f1-score: 0.7793, diff_precision: 0.8813, diff_recall: 0.8047, diff_f1-score: 0.8412, same_precision: 0.5277, same_recall: 0.6682, same_f1-score: 0.5897, batch_loss: 0.0671, loss: 0.5535 ||:   7%|6         | 857/12754 [10:01<2:18:08,  1.44it/s]
2025-05-27 20:16:09,840 - INFO - tqdm - accuracy: 0.7746, precision: 0.7968, recall: 0.7746, f1-score: 0.7825, diff_precision: 0.8828, diff_recall: 0.8081, diff_f1-score: 0.8438, same_precision: 0.5336, same_recall: 0.6718, same_f1-score: 0.5948, batch_loss: 0.6127, loss: 0.5466 ||:   7%|6         | 873/12754 [10:11<1:53:14,  1.75it/s]
2025-05-27 20:16:20,288 - INFO - tqdm - accuracy: 0.7773, precision: 0.7991, recall: 0.7773, f1-score: 0.7851, diff_precision: 0.8844, diff_recall: 0.8111, diff_f1-score: 0.8462, same_precision: 0.5357, same_recall: 0.6728, same_f1-score: 0.5965, batch_loss: 0.0976, loss: 0.5411 ||:   7%|6         | 887/12754 [10:21<2:19:59,  1.41it/s]
2025-05-27 20:16:30,498 - INFO - tqdm - accuracy: 0.7798, precision: 0.8008, recall: 0.7798, f1-score: 0.7873, diff_precision: 0.8853, diff_recall: 0.8138, diff_f1-score: 0.8480, same_precision: 0.5405, same_recall: 0.6751, same_f1-score: 0.6004, batch_loss: 0.0664, loss: 0.5361 ||:   7%|7         | 902/12754 [10:32<1:56:34,  1.69it/s]
2025-05-27 20:16:40,615 - INFO - tqdm - accuracy: 0.7823, precision: 0.8032, recall: 0.7823, f1-score: 0.7898, diff_precision: 0.8871, diff_recall: 0.8162, diff_f1-score: 0.8502, same_precision: 0.5424, same_recall: 0.6771, same_f1-score: 0.6023, batch_loss: 0.1494, loss: 0.5302 ||:   7%|7         | 916/12754 [10:42<2:36:47,  1.26it/s]
2025-05-27 20:16:51,215 - INFO - tqdm - accuracy: 0.7845, precision: 0.8043, recall: 0.7845, f1-score: 0.7917, diff_precision: 0.8873, diff_recall: 0.8188, diff_f1-score: 0.8517, same_precision: 0.5482, same_recall: 0.6787, same_f1-score: 0.6065, batch_loss: 0.0578, loss: 0.5256 ||:   7%|7         | 932/12754 [10:52<2:14:44,  1.46it/s]
2025-05-27 20:17:01,483 - INFO - tqdm - accuracy: 0.7871, precision: 0.8062, recall: 0.7871, f1-score: 0.7940, diff_precision: 0.8882, diff_recall: 0.8211, diff_f1-score: 0.8533, same_precision: 0.5543, same_recall: 0.6829, same_f1-score: 0.6119, batch_loss: 0.0251, loss: 0.5204 ||:   7%|7         | 948/12754 [11:03<1:59:43,  1.64it/s]
2025-05-27 20:17:11,888 - INFO - tqdm - accuracy: 0.7900, precision: 0.8087, recall: 0.7900, f1-score: 0.7968, diff_precision: 0.8900, diff_recall: 0.8242, diff_f1-score: 0.8558, same_precision: 0.5568, same_recall: 0.6843, same_f1-score: 0.6140, batch_loss: 0.0054, loss: 0.5140 ||:   8%|7         | 963/12754 [11:13<2:34:32,  1.27it/s]
2025-05-27 20:17:22,023 - INFO - tqdm - accuracy: 0.7925, precision: 0.8107, recall: 0.7925, f1-score: 0.7991, diff_precision: 0.8913, diff_recall: 0.8269, diff_f1-score: 0.8579, same_precision: 0.5590, same_recall: 0.6851, same_f1-score: 0.6156, batch_loss: 0.2535, loss: 0.5090 ||:   8%|7         | 977/12754 [11:23<2:09:03,  1.52it/s]
2025-05-27 20:17:32,522 - INFO - tqdm - accuracy: 0.7949, precision: 0.8130, recall: 0.7949, f1-score: 0.8015, diff_precision: 0.8930, diff_recall: 0.8290, diff_f1-score: 0.8598, same_precision: 0.5610, same_recall: 0.6875, same_f1-score: 0.6179, batch_loss: 0.1671, loss: 0.5032 ||:   8%|7         | 991/12754 [11:34<2:37:29,  1.24it/s]
2025-05-27 20:17:43,049 - INFO - tqdm - accuracy: 0.7965, precision: 0.8136, recall: 0.7965, f1-score: 0.8028, diff_precision: 0.8928, diff_recall: 0.8307, diff_f1-score: 0.8606, same_precision: 0.5680, same_recall: 0.6906, same_f1-score: 0.6233, batch_loss: 0.1035, loss: 0.5008 ||:   8%|7         | 1005/12754 [11:44<2:16:57,  1.43it/s]
2025-05-27 20:17:53,604 - INFO - tqdm - accuracy: 0.7980, precision: 0.8146, recall: 0.7980, f1-score: 0.8040, diff_precision: 0.8932, diff_recall: 0.8321, diff_f1-score: 0.8616, same_precision: 0.5715, same_recall: 0.6923, same_f1-score: 0.6261, batch_loss: 0.0596, loss: 0.4980 ||:   8%|7         | 1019/12754 [11:55<2:41:34,  1.21it/s]
2025-05-27 20:18:04,071 - INFO - tqdm - accuracy: 0.8002, precision: 0.8163, recall: 0.8002, f1-score: 0.8061, diff_precision: 0.8942, diff_recall: 0.8343, diff_f1-score: 0.8633, same_precision: 0.5749, same_recall: 0.6942, same_f1-score: 0.6289, batch_loss: 0.0205, loss: 0.4928 ||:   8%|8         | 1033/12754 [12:05<2:20:03,  1.39it/s]
2025-05-27 20:18:14,500 - INFO - tqdm - accuracy: 0.8021, precision: 0.8178, recall: 0.8021, f1-score: 0.8079, diff_precision: 0.8950, diff_recall: 0.8363, diff_f1-score: 0.8646, same_precision: 0.5790, same_recall: 0.6963, same_f1-score: 0.6322, batch_loss: 0.0732, loss: 0.4891 ||:   8%|8         | 1048/12754 [12:16<2:10:57,  1.49it/s]
2025-05-27 20:18:24,594 - INFO - tqdm - accuracy: 0.8044, precision: 0.8195, recall: 0.8044, f1-score: 0.8100, diff_precision: 0.8959, diff_recall: 0.8382, diff_f1-score: 0.8661, same_precision: 0.5850, same_recall: 0.7007, same_f1-score: 0.6376, batch_loss: 0.2138, loss: 0.4841 ||:   8%|8         | 1063/12754 [12:26<2:10:04,  1.50it/s]
2025-05-27 20:18:35,054 - INFO - tqdm - accuracy: 0.8058, precision: 0.8205, recall: 0.8058, f1-score: 0.8112, diff_precision: 0.8962, diff_recall: 0.8394, diff_f1-score: 0.8669, same_precision: 0.5896, same_recall: 0.7035, same_f1-score: 0.6415, batch_loss: 0.0458, loss: 0.4809 ||:   8%|8         | 1077/12754 [12:36<2:30:37,  1.29it/s]
2025-05-27 20:18:45,643 - INFO - tqdm - accuracy: 0.8075, precision: 0.8214, recall: 0.8075, f1-score: 0.8126, diff_precision: 0.8964, diff_recall: 0.8411, diff_f1-score: 0.8678, same_precision: 0.5948, same_recall: 0.7057, same_f1-score: 0.6455, batch_loss: 0.0177, loss: 0.4780 ||:   9%|8         | 1091/12754 [12:47<2:21:23,  1.37it/s]
2025-05-27 20:18:55,792 - INFO - tqdm - accuracy: 0.8094, precision: 0.8229, recall: 0.8094, f1-score: 0.8144, diff_precision: 0.8972, diff_recall: 0.8428, diff_f1-score: 0.8692, same_precision: 0.5990, same_recall: 0.7084, same_f1-score: 0.6491, batch_loss: 0.5074, loss: 0.4740 ||:   9%|8         | 1105/12754 [12:57<1:59:43,  1.62it/s]
2025-05-27 20:19:05,793 - INFO - tqdm - accuracy: 0.8117, precision: 0.8250, recall: 0.8117, f1-score: 0.8166, diff_precision: 0.8986, diff_recall: 0.8451, diff_f1-score: 0.8711, same_precision: 0.6010, same_recall: 0.7098, same_f1-score: 0.6509, batch_loss: 0.1206, loss: 0.4685 ||:   9%|8         | 1120/12754 [13:07<2:26:39,  1.32it/s]
2025-05-27 20:19:16,292 - INFO - tqdm - accuracy: 0.8131, precision: 0.8259, recall: 0.8131, f1-score: 0.8178, diff_precision: 0.8988, diff_recall: 0.8465, diff_f1-score: 0.8719, same_precision: 0.6055, same_recall: 0.7121, same_f1-score: 0.6545, batch_loss: 0.0717, loss: 0.4657 ||:   9%|8         | 1134/12754 [13:18<2:22:41,  1.36it/s]
2025-05-27 20:19:26,782 - INFO - tqdm - accuracy: 0.8147, precision: 0.8269, recall: 0.8147, f1-score: 0.8192, diff_precision: 0.8990, diff_recall: 0.8477, diff_f1-score: 0.8726, same_precision: 0.6119, same_recall: 0.7160, same_f1-score: 0.6599, batch_loss: 0.2884, loss: 0.4619 ||:   9%|9         | 1151/12754 [13:28<1:56:50,  1.66it/s]
2025-05-27 20:19:37,124 - INFO - tqdm - accuracy: 0.8162, precision: 0.8283, recall: 0.8162, f1-score: 0.8207, diff_precision: 0.8999, diff_recall: 0.8495, diff_f1-score: 0.8740, same_precision: 0.6131, same_recall: 0.7163, same_f1-score: 0.6607, batch_loss: 0.1156, loss: 0.4586 ||:   9%|9         | 1165/12754 [13:38<2:21:17,  1.37it/s]
2025-05-27 20:19:47,158 - INFO - tqdm - accuracy: 0.8180, precision: 0.8295, recall: 0.8180, f1-score: 0.8223, diff_precision: 0.9002, diff_recall: 0.8505, diff_f1-score: 0.8747, same_precision: 0.6212, same_recall: 0.7222, same_f1-score: 0.6679, batch_loss: 0.5100, loss: 0.4548 ||:   9%|9         | 1180/12754 [13:48<2:32:54,  1.26it/s]
2025-05-27 20:19:57,200 - INFO - tqdm - accuracy: 0.8202, precision: 0.8315, recall: 0.8202, f1-score: 0.8244, diff_precision: 0.9016, diff_recall: 0.8527, diff_f1-score: 0.8765, same_precision: 0.6232, same_recall: 0.7236, same_f1-score: 0.6697, batch_loss: 0.4707, loss: 0.4501 ||:   9%|9         | 1195/12754 [13:58<1:55:11,  1.67it/s]
2025-05-27 20:20:07,355 - INFO - tqdm - accuracy: 0.8215, precision: 0.8323, recall: 0.8215, f1-score: 0.8256, diff_precision: 0.9017, diff_recall: 0.8542, diff_f1-score: 0.8773, same_precision: 0.6276, same_recall: 0.7253, same_f1-score: 0.6729, batch_loss: 0.5646, loss: 0.4471 ||:   9%|9         | 1209/12754 [14:09<2:21:20,  1.36it/s]
2025-05-27 20:20:17,600 - INFO - tqdm - accuracy: 0.8231, precision: 0.8338, recall: 0.8231, f1-score: 0.8271, diff_precision: 0.9027, diff_recall: 0.8554, diff_f1-score: 0.8784, same_precision: 0.6298, same_recall: 0.7273, same_f1-score: 0.6751, batch_loss: 0.0574, loss: 0.4432 ||:  10%|9         | 1223/12754 [14:19<2:14:37,  1.43it/s]
2025-05-27 20:20:27,640 - INFO - tqdm - accuracy: 0.8245, precision: 0.8349, recall: 0.8245, f1-score: 0.8283, diff_precision: 0.9032, diff_recall: 0.8568, diff_f1-score: 0.8794, same_precision: 0.6330, same_recall: 0.7290, same_f1-score: 0.6776, batch_loss: 0.1349, loss: 0.4406 ||:  10%|9         | 1237/12754 [14:29<2:24:55,  1.32it/s]
2025-05-27 20:20:37,827 - INFO - tqdm - accuracy: 0.8262, precision: 0.8364, recall: 0.8262, f1-score: 0.8300, diff_precision: 0.9043, diff_recall: 0.8584, diff_f1-score: 0.8807, same_precision: 0.6353, same_recall: 0.7308, same_f1-score: 0.6797, batch_loss: 0.0110, loss: 0.4367 ||:  10%|9         | 1252/12754 [14:39<2:10:10,  1.47it/s]
2025-05-27 20:20:48,291 - INFO - tqdm - accuracy: 0.8276, precision: 0.8376, recall: 0.8276, f1-score: 0.8313, diff_precision: 0.9050, diff_recall: 0.8601, diff_f1-score: 0.8820, same_precision: 0.6366, same_recall: 0.7307, same_f1-score: 0.6805, batch_loss: 0.0226, loss: 0.4336 ||:  10%|9         | 1266/12754 [14:49<2:31:26,  1.26it/s]
2025-05-27 20:20:58,559 - INFO - tqdm - accuracy: 0.8292, precision: 0.8391, recall: 0.8292, f1-score: 0.8329, diff_precision: 0.9060, diff_recall: 0.8617, diff_f1-score: 0.8833, same_precision: 0.6379, same_recall: 0.7316, same_f1-score: 0.6816, batch_loss: 0.0066, loss: 0.4298 ||:  10%|#         | 1281/12754 [15:00<2:03:17,  1.55it/s]
2025-05-27 20:21:08,857 - INFO - tqdm - accuracy: 0.8309, precision: 0.8405, recall: 0.8309, f1-score: 0.8346, diff_precision: 0.9070, diff_recall: 0.8636, diff_f1-score: 0.8848, same_precision: 0.6395, same_recall: 0.7321, same_f1-score: 0.6827, batch_loss: 0.0054, loss: 0.4268 ||:  10%|#         | 1296/12754 [15:10<2:07:46,  1.49it/s]
2025-05-27 20:21:18,913 - INFO - tqdm - accuracy: 0.8320, precision: 0.8411, recall: 0.8320, f1-score: 0.8355, diff_precision: 0.9069, diff_recall: 0.8648, diff_f1-score: 0.8853, same_precision: 0.6442, same_recall: 0.7338, same_f1-score: 0.6861, batch_loss: 0.1443, loss: 0.4257 ||:  10%|#         | 1311/12754 [15:20<2:01:18,  1.57it/s]
2025-05-27 20:21:29,080 - INFO - tqdm - accuracy: 0.8334, precision: 0.8424, recall: 0.8334, f1-score: 0.8368, diff_precision: 0.9077, diff_recall: 0.8661, diff_f1-score: 0.8864, same_precision: 0.6456, same_recall: 0.7348, same_f1-score: 0.6873, batch_loss: 0.0160, loss: 0.4226 ||:  10%|#         | 1324/12754 [15:30<2:33:00,  1.25it/s]
2025-05-27 20:21:39,262 - INFO - tqdm - accuracy: 0.8345, precision: 0.8433, recall: 0.8345, f1-score: 0.8379, diff_precision: 0.9081, diff_recall: 0.8675, diff_f1-score: 0.8873, same_precision: 0.6477, same_recall: 0.7350, same_f1-score: 0.6886, batch_loss: 0.0331, loss: 0.4208 ||:  10%|#         | 1338/12754 [15:40<2:09:18,  1.47it/s]
2025-05-27 20:21:49,408 - INFO - tqdm - accuracy: 0.8352, precision: 0.8437, recall: 0.8352, f1-score: 0.8384, diff_precision: 0.9081, diff_recall: 0.8682, diff_f1-score: 0.8877, same_precision: 0.6498, same_recall: 0.7357, same_f1-score: 0.6901, batch_loss: 0.0773, loss: 0.4187 ||:  11%|#         | 1351/12754 [15:51<2:19:02,  1.37it/s]
2025-05-27 20:21:59,679 - INFO - tqdm - accuracy: 0.8365, precision: 0.8447, recall: 0.8365, f1-score: 0.8396, diff_precision: 0.9085, diff_recall: 0.8696, diff_f1-score: 0.8887, same_precision: 0.6528, same_recall: 0.7368, same_f1-score: 0.6923, batch_loss: 1.3162, loss: 0.4163 ||:  11%|#         | 1366/12754 [16:01<2:02:44,  1.55it/s]
2025-05-27 20:22:10,177 - INFO - tqdm - accuracy: 0.8383, precision: 0.8464, recall: 0.8383, f1-score: 0.8414, diff_precision: 0.9097, diff_recall: 0.8714, diff_f1-score: 0.8901, same_precision: 0.6545, same_recall: 0.7380, same_f1-score: 0.6937, batch_loss: 0.0278, loss: 0.4122 ||:  11%|#         | 1382/12754 [16:11<2:01:14,  1.56it/s]
2025-05-27 20:22:20,988 - INFO - tqdm - accuracy: 0.8394, precision: 0.8471, recall: 0.8394, f1-score: 0.8424, diff_precision: 0.9098, diff_recall: 0.8724, diff_f1-score: 0.8907, same_precision: 0.6590, same_recall: 0.7402, same_f1-score: 0.6972, batch_loss: 0.2039, loss: 0.4098 ||:  11%|#         | 1397/12754 [16:22<2:26:36,  1.29it/s]
2025-05-27 20:22:31,566 - INFO - tqdm - accuracy: 0.8409, precision: 0.8485, recall: 0.8409, f1-score: 0.8438, diff_precision: 0.9107, diff_recall: 0.8736, diff_f1-score: 0.8917, same_precision: 0.6620, same_recall: 0.7429, same_f1-score: 0.7002, batch_loss: 0.0363, loss: 0.4063 ||:  11%|#1        | 1412/12754 [16:33<2:30:41,  1.25it/s]
2025-05-27 20:22:42,130 - INFO - tqdm - accuracy: 0.8415, precision: 0.8487, recall: 0.8415, f1-score: 0.8443, diff_precision: 0.9101, diff_recall: 0.8745, diff_f1-score: 0.8919, same_precision: 0.6666, same_recall: 0.7439, same_f1-score: 0.7032, batch_loss: 0.3805, loss: 0.4050 ||:  11%|#1        | 1427/12754 [16:43<2:05:28,  1.50it/s]
2025-05-27 20:22:52,471 - INFO - tqdm - accuracy: 0.8428, precision: 0.8498, recall: 0.8428, f1-score: 0.8455, diff_precision: 0.9108, diff_recall: 0.8756, diff_f1-score: 0.8928, same_precision: 0.6691, same_recall: 0.7457, same_f1-score: 0.7053, batch_loss: 0.0258, loss: 0.4021 ||:  11%|#1        | 1443/12754 [16:54<1:58:27,  1.59it/s]
2025-05-27 20:23:03,152 - INFO - tqdm - accuracy: 0.8440, precision: 0.8508, recall: 0.8440, f1-score: 0.8466, diff_precision: 0.9113, diff_recall: 0.8767, diff_f1-score: 0.8937, same_precision: 0.6717, same_recall: 0.7471, same_f1-score: 0.7074, batch_loss: 0.4511, loss: 0.3995 ||:  11%|#1        | 1458/12754 [17:04<2:23:03,  1.32it/s]
2025-05-27 20:23:13,534 - INFO - tqdm - accuracy: 0.8453, precision: 0.8520, recall: 0.8453, f1-score: 0.8479, diff_precision: 0.9120, diff_recall: 0.8778, diff_f1-score: 0.8946, same_precision: 0.6745, same_recall: 0.7492, same_f1-score: 0.7099, batch_loss: 0.1024, loss: 0.3962 ||:  12%|#1        | 1473/12754 [17:15<2:21:14,  1.33it/s]
2025-05-27 20:23:23,928 - INFO - tqdm - accuracy: 0.8463, precision: 0.8527, recall: 0.8463, f1-score: 0.8488, diff_precision: 0.9122, diff_recall: 0.8787, diff_f1-score: 0.8951, same_precision: 0.6774, same_recall: 0.7507, same_f1-score: 0.7122, batch_loss: 0.0176, loss: 0.3938 ||:  12%|#1        | 1488/12754 [17:25<2:23:23,  1.31it/s]
2025-05-27 20:23:34,330 - INFO - tqdm - accuracy: 0.8470, precision: 0.8533, recall: 0.8470, f1-score: 0.8495, diff_precision: 0.9122, diff_recall: 0.8793, diff_f1-score: 0.8955, same_precision: 0.6810, same_recall: 0.7528, same_f1-score: 0.7151, batch_loss: 0.0574, loss: 0.3919 ||:  12%|#1        | 1502/12754 [17:36<2:22:19,  1.32it/s]
2025-05-27 20:23:44,806 - INFO - tqdm - accuracy: 0.8482, precision: 0.8543, recall: 0.8482, f1-score: 0.8506, diff_precision: 0.9129, diff_recall: 0.8805, diff_f1-score: 0.8964, same_precision: 0.6828, same_recall: 0.7537, same_f1-score: 0.7165, batch_loss: 0.0094, loss: 0.3889 ||:  12%|#1        | 1517/12754 [17:46<2:12:57,  1.41it/s]
2025-05-27 20:23:55,090 - INFO - tqdm - accuracy: 0.8495, precision: 0.8556, recall: 0.8495, f1-score: 0.8519, diff_precision: 0.9139, diff_recall: 0.8818, diff_f1-score: 0.8975, same_precision: 0.6831, same_recall: 0.7542, same_f1-score: 0.7169, batch_loss: 0.0018, loss: 0.3855 ||:  12%|#2        | 1532/12754 [17:56<2:19:44,  1.34it/s]
2025-05-27 20:24:05,482 - INFO - tqdm - accuracy: 0.8506, precision: 0.8565, recall: 0.8506, f1-score: 0.8530, diff_precision: 0.9145, diff_recall: 0.8830, diff_f1-score: 0.8985, same_precision: 0.6843, same_recall: 0.7543, same_f1-score: 0.7176, batch_loss: 0.0052, loss: 0.3833 ||:  12%|#2        | 1546/12754 [18:07<2:13:12,  1.40it/s]
2025-05-27 20:24:16,083 - INFO - tqdm - accuracy: 0.8516, precision: 0.8573, recall: 0.8516, f1-score: 0.8539, diff_precision: 0.9147, diff_recall: 0.8837, diff_f1-score: 0.8990, same_precision: 0.6878, same_recall: 0.7566, same_f1-score: 0.7206, batch_loss: 0.0199, loss: 0.3812 ||:  12%|#2        | 1562/12754 [18:17<1:56:10,  1.61it/s]
2025-05-27 20:24:26,637 - INFO - tqdm - accuracy: 0.8528, precision: 0.8585, recall: 0.8528, f1-score: 0.8550, diff_precision: 0.9155, diff_recall: 0.8848, diff_f1-score: 0.8999, same_precision: 0.6895, same_recall: 0.7582, same_f1-score: 0.7222, batch_loss: 0.0029, loss: 0.3782 ||:  12%|#2        | 1577/12754 [18:28<2:27:23,  1.26it/s]
2025-05-27 20:24:37,005 - INFO - tqdm - accuracy: 0.8538, precision: 0.8593, recall: 0.8538, f1-score: 0.8560, diff_precision: 0.9158, diff_recall: 0.8857, diff_f1-score: 0.9005, same_precision: 0.6926, same_recall: 0.7596, same_f1-score: 0.7246, batch_loss: 0.0362, loss: 0.3761 ||:  12%|#2        | 1592/12754 [18:38<2:11:29,  1.41it/s]
2025-05-27 20:24:47,232 - INFO - tqdm - accuracy: 0.8551, precision: 0.8606, recall: 0.8551, f1-score: 0.8573, diff_precision: 0.9168, diff_recall: 0.8870, diff_f1-score: 0.9016, same_precision: 0.6932, same_recall: 0.7602, same_f1-score: 0.7252, batch_loss: 0.0101, loss: 0.3728 ||:  13%|#2        | 1607/12754 [18:48<2:14:28,  1.38it/s]
2025-05-27 20:24:57,693 - INFO - tqdm - accuracy: 0.8558, precision: 0.8611, recall: 0.8558, f1-score: 0.8579, diff_precision: 0.9169, diff_recall: 0.8878, diff_f1-score: 0.9021, same_precision: 0.6949, same_recall: 0.7607, same_f1-score: 0.7263, batch_loss: 0.0444, loss: 0.3709 ||:  13%|#2        | 1622/12754 [18:59<2:07:13,  1.46it/s]
2025-05-27 20:25:08,081 - INFO - tqdm - accuracy: 0.8568, precision: 0.8618, recall: 0.8568, f1-score: 0.8588, diff_precision: 0.9171, diff_recall: 0.8886, diff_f1-score: 0.9026, same_precision: 0.6986, same_recall: 0.7627, same_f1-score: 0.7292, batch_loss: 0.0055, loss: 0.3689 ||:  13%|#2        | 1637/12754 [19:09<2:06:00,  1.47it/s]
2025-05-27 20:25:18,576 - INFO - tqdm - accuracy: 0.8576, precision: 0.8626, recall: 0.8576, f1-score: 0.8596, diff_precision: 0.9176, diff_recall: 0.8893, diff_f1-score: 0.9032, same_precision: 0.6998, same_recall: 0.7638, same_f1-score: 0.7304, batch_loss: 0.0080, loss: 0.3671 ||:  13%|#2        | 1651/12754 [19:20<2:21:14,  1.31it/s]
2025-05-27 20:25:28,831 - INFO - tqdm - accuracy: 0.8581, precision: 0.8629, recall: 0.8581, f1-score: 0.8601, diff_precision: 0.9174, diff_recall: 0.8897, diff_f1-score: 0.9033, same_precision: 0.7041, same_recall: 0.7662, same_f1-score: 0.7339, batch_loss: 0.0585, loss: 0.3662 ||:  13%|#3        | 1665/12754 [19:30<2:03:29,  1.50it/s]
2025-05-27 20:25:38,950 - INFO - tqdm - accuracy: 0.8593, precision: 0.8640, recall: 0.8593, f1-score: 0.8612, diff_precision: 0.9182, diff_recall: 0.8907, diff_f1-score: 0.9042, same_precision: 0.7053, same_recall: 0.7673, same_f1-score: 0.7350, batch_loss: 0.0097, loss: 0.3637 ||:  13%|#3        | 1679/12754 [19:40<2:21:17,  1.31it/s]
2025-05-27 20:25:49,240 - INFO - tqdm - accuracy: 0.8603, precision: 0.8651, recall: 0.8603, f1-score: 0.8622, diff_precision: 0.9189, diff_recall: 0.8916, diff_f1-score: 0.9050, same_precision: 0.7065, same_recall: 0.7684, same_f1-score: 0.7361, batch_loss: 0.0026, loss: 0.3611 ||:  13%|#3        | 1692/12754 [19:50<2:43:54,  1.12it/s]
2025-05-27 20:25:59,771 - INFO - tqdm - accuracy: 0.8612, precision: 0.8658, recall: 0.8612, f1-score: 0.8631, diff_precision: 0.9193, diff_recall: 0.8925, diff_f1-score: 0.9057, same_precision: 0.7081, same_recall: 0.7690, same_f1-score: 0.7373, batch_loss: 0.0050, loss: 0.3590 ||:  13%|#3        | 1706/12754 [20:01<2:19:39,  1.32it/s]
2025-05-27 20:26:10,341 - INFO - tqdm - accuracy: 0.8619, precision: 0.8663, recall: 0.8619, f1-score: 0.8637, diff_precision: 0.9193, diff_recall: 0.8932, diff_f1-score: 0.9061, same_precision: 0.7112, same_recall: 0.7703, same_f1-score: 0.7396, batch_loss: 0.0006, loss: 0.3578 ||:  13%|#3        | 1721/12754 [20:12<2:18:03,  1.33it/s]
2025-05-27 20:26:20,730 - INFO - tqdm - accuracy: 0.8625, precision: 0.8669, recall: 0.8625, f1-score: 0.8642, diff_precision: 0.9197, diff_recall: 0.8933, diff_f1-score: 0.9063, same_precision: 0.7130, same_recall: 0.7727, same_f1-score: 0.7417, batch_loss: 0.0172, loss: 0.3561 ||:  14%|#3        | 1738/12754 [20:22<1:44:01,  1.76it/s]
2025-05-27 20:26:30,969 - INFO - tqdm - accuracy: 0.8632, precision: 0.8675, recall: 0.8632, f1-score: 0.8649, diff_precision: 0.9198, diff_recall: 0.8940, diff_f1-score: 0.9067, same_precision: 0.7156, same_recall: 0.7739, same_f1-score: 0.7436, batch_loss: 0.1371, loss: 0.3547 ||:  14%|#3        | 1752/12754 [20:32<2:01:47,  1.51it/s]
2025-05-27 20:26:41,418 - INFO - tqdm - accuracy: 0.8642, precision: 0.8685, recall: 0.8642, f1-score: 0.8659, diff_precision: 0.9207, diff_recall: 0.8949, diff_f1-score: 0.9076, same_precision: 0.7157, same_recall: 0.7744, same_f1-score: 0.7439, batch_loss: 0.0317, loss: 0.3520 ||:  14%|#3        | 1767/12754 [20:43<2:03:25,  1.48it/s]
2025-05-27 20:26:51,769 - INFO - tqdm - accuracy: 0.8652, precision: 0.8694, recall: 0.8652, f1-score: 0.8669, diff_precision: 0.9214, diff_recall: 0.8958, diff_f1-score: 0.9084, same_precision: 0.7168, same_recall: 0.7752, same_f1-score: 0.7448, batch_loss: 0.0016, loss: 0.3495 ||:  14%|#3        | 1781/12754 [20:53<2:12:40,  1.38it/s]
2025-05-27 20:27:02,495 - INFO - tqdm - accuracy: 0.8661, precision: 0.8702, recall: 0.8661, f1-score: 0.8677, diff_precision: 0.9217, diff_recall: 0.8967, diff_f1-score: 0.9090, same_precision: 0.7188, same_recall: 0.7762, same_f1-score: 0.7464, batch_loss: 0.0094, loss: 0.3479 ||:  14%|#4        | 1796/12754 [21:04<2:27:08,  1.24it/s]
2025-05-27 20:27:12,701 - INFO - tqdm - accuracy: 0.8669, precision: 0.8708, recall: 0.8669, f1-score: 0.8685, diff_precision: 0.9220, diff_recall: 0.8975, diff_f1-score: 0.9096, same_precision: 0.7203, same_recall: 0.7766, same_f1-score: 0.7473, batch_loss: 0.0074, loss: 0.3462 ||:  14%|#4        | 1810/12754 [21:14<2:15:55,  1.34it/s]
2025-05-27 20:27:23,379 - INFO - tqdm - accuracy: 0.8678, precision: 0.8718, recall: 0.8678, f1-score: 0.8694, diff_precision: 0.9226, diff_recall: 0.8984, diff_f1-score: 0.9104, same_precision: 0.7213, same_recall: 0.7773, same_f1-score: 0.7482, batch_loss: 0.0241, loss: 0.3440 ||:  14%|#4        | 1824/12754 [21:25<2:27:33,  1.23it/s]
2025-05-27 20:27:33,442 - INFO - tqdm - accuracy: 0.8686, precision: 0.8725, recall: 0.8686, f1-score: 0.8702, diff_precision: 0.9230, diff_recall: 0.8991, diff_f1-score: 0.9109, same_precision: 0.7231, same_recall: 0.7785, same_f1-score: 0.7498, batch_loss: 0.1194, loss: 0.3419 ||:  14%|#4        | 1839/12754 [21:35<1:59:44,  1.52it/s]
2025-05-27 20:27:43,509 - INFO - tqdm - accuracy: 0.8694, precision: 0.8732, recall: 0.8694, f1-score: 0.8709, diff_precision: 0.9235, diff_recall: 0.9000, diff_f1-score: 0.9116, same_precision: 0.7240, same_recall: 0.7786, same_f1-score: 0.7503, batch_loss: 0.0228, loss: 0.3402 ||:  15%|#4        | 1853/12754 [21:45<2:13:05,  1.37it/s]
2025-05-27 20:27:53,634 - INFO - tqdm - accuracy: 0.8699, precision: 0.8736, recall: 0.8699, f1-score: 0.8714, diff_precision: 0.9236, diff_recall: 0.9006, diff_f1-score: 0.9119, same_precision: 0.7255, same_recall: 0.7791, same_f1-score: 0.7513, batch_loss: 0.1097, loss: 0.3394 ||:  15%|#4        | 1867/12754 [21:55<2:11:42,  1.38it/s]
2025-05-27 20:28:03,738 - INFO - tqdm - accuracy: 0.8708, precision: 0.8744, recall: 0.8708, f1-score: 0.8723, diff_precision: 0.9241, diff_recall: 0.9013, diff_f1-score: 0.9125, same_precision: 0.7270, same_recall: 0.7802, same_f1-score: 0.7527, batch_loss: 0.0142, loss: 0.3373 ||:  15%|#4        | 1881/12754 [22:05<2:11:54,  1.37it/s]
2025-05-27 20:28:13,742 - INFO - tqdm - accuracy: 0.8716, precision: 0.8752, recall: 0.8716, f1-score: 0.8731, diff_precision: 0.9245, diff_recall: 0.9021, diff_f1-score: 0.9131, same_precision: 0.7290, same_recall: 0.7814, same_f1-score: 0.7543, batch_loss: 0.0523, loss: 0.3351 ||:  15%|#4        | 1896/12754 [22:15<2:09:09,  1.40it/s]
2025-05-27 20:28:24,148 - INFO - tqdm - accuracy: 0.8725, precision: 0.8759, recall: 0.8725, f1-score: 0.8739, diff_precision: 0.9248, diff_recall: 0.9028, diff_f1-score: 0.9137, same_precision: 0.7313, same_recall: 0.7829, same_f1-score: 0.7562, batch_loss: 0.0122, loss: 0.3330 ||:  15%|#4        | 1912/12754 [22:25<1:52:19,  1.61it/s]
2025-05-27 20:28:34,536 - INFO - tqdm - accuracy: 0.8731, precision: 0.8765, recall: 0.8731, f1-score: 0.8745, diff_precision: 0.9252, diff_recall: 0.9034, diff_f1-score: 0.9142, same_precision: 0.7323, same_recall: 0.7833, same_f1-score: 0.7569, batch_loss: 0.0032, loss: 0.3319 ||:  15%|#5        | 1927/12754 [22:36<2:00:08,  1.50it/s]
2025-05-27 20:28:45,029 - INFO - tqdm - accuracy: 0.8739, precision: 0.8772, recall: 0.8739, f1-score: 0.8752, diff_precision: 0.9254, diff_recall: 0.9041, diff_f1-score: 0.9146, same_precision: 0.7346, same_recall: 0.7848, same_f1-score: 0.7589, batch_loss: 0.0175, loss: 0.3301 ||:  15%|#5        | 1942/12754 [22:46<2:01:46,  1.48it/s]
2025-05-27 20:28:55,357 - INFO - tqdm - accuracy: 0.8747, precision: 0.8779, recall: 0.8747, f1-score: 0.8760, diff_precision: 0.9259, diff_recall: 0.9047, diff_f1-score: 0.9152, same_precision: 0.7358, same_recall: 0.7857, same_f1-score: 0.7599, batch_loss: 0.0042, loss: 0.3282 ||:  15%|#5        | 1957/12754 [22:57<2:03:02,  1.46it/s]
2025-05-27 20:29:05,935 - INFO - tqdm - accuracy: 0.8755, precision: 0.8787, recall: 0.8755, f1-score: 0.8768, diff_precision: 0.9263, diff_recall: 0.9054, diff_f1-score: 0.9157, same_precision: 0.7376, same_recall: 0.7869, same_f1-score: 0.7614, batch_loss: 0.0082, loss: 0.3262 ||:  15%|#5        | 1972/12754 [23:07<2:14:00,  1.34it/s]
2025-05-27 20:29:16,141 - INFO - tqdm - accuracy: 0.8761, precision: 0.8792, recall: 0.8761, f1-score: 0.8774, diff_precision: 0.9265, diff_recall: 0.9059, diff_f1-score: 0.9161, same_precision: 0.7402, same_recall: 0.7887, same_f1-score: 0.7637, batch_loss: 0.0666, loss: 0.3246 ||:  16%|#5        | 1986/12754 [23:17<2:12:54,  1.35it/s]
2025-05-27 20:29:26,190 - INFO - tqdm - accuracy: 0.8768, precision: 0.8799, recall: 0.8768, f1-score: 0.8781, diff_precision: 0.9268, diff_recall: 0.9063, diff_f1-score: 0.9164, same_precision: 0.7427, same_recall: 0.7907, same_f1-score: 0.7660, batch_loss: 0.1263, loss: 0.3228 ||:  16%|#5        | 2001/12754 [23:27<2:03:40,  1.45it/s]
2025-05-27 20:29:36,807 - INFO - tqdm - accuracy: 0.8773, precision: 0.8804, recall: 0.8773, f1-score: 0.8786, diff_precision: 0.9274, diff_recall: 0.9066, diff_f1-score: 0.9169, same_precision: 0.7421, same_recall: 0.7910, same_f1-score: 0.7657, batch_loss: 0.0002, loss: 0.3210 ||:  16%|#5        | 2016/12754 [23:38<2:15:50,  1.32it/s]
2025-05-27 20:29:47,077 - INFO - tqdm - accuracy: 0.8778, precision: 0.8807, recall: 0.8778, f1-score: 0.8790, diff_precision: 0.9273, diff_recall: 0.9071, diff_f1-score: 0.9171, same_precision: 0.7444, same_recall: 0.7919, same_f1-score: 0.7675, batch_loss: 0.1113, loss: 0.3205 ||:  16%|#5        | 2030/12754 [23:48<1:59:28,  1.50it/s]
2025-05-27 20:29:57,202 - INFO - tqdm - accuracy: 0.8782, precision: 0.8811, recall: 0.8782, f1-score: 0.8794, diff_precision: 0.9274, diff_recall: 0.9073, diff_f1-score: 0.9173, same_precision: 0.7465, same_recall: 0.7935, same_f1-score: 0.7693, batch_loss: 0.0164, loss: 0.3195 ||:  16%|#6        | 2044/12754 [23:58<1:51:06,  1.61it/s]
2025-05-27 20:30:07,900 - INFO - tqdm - accuracy: 0.8789, precision: 0.8818, recall: 0.8789, f1-score: 0.8801, diff_precision: 0.9278, diff_recall: 0.9080, diff_f1-score: 0.9178, same_precision: 0.7477, same_recall: 0.7942, same_f1-score: 0.7702, batch_loss: 0.0058, loss: 0.3178 ||:  16%|#6        | 2058/12754 [24:09<2:29:56,  1.19it/s]
2025-05-27 20:30:18,263 - INFO - tqdm - accuracy: 0.8796, precision: 0.8823, recall: 0.8796, f1-score: 0.8807, diff_precision: 0.9281, diff_recall: 0.9086, diff_f1-score: 0.9182, same_precision: 0.7492, same_recall: 0.7949, same_f1-score: 0.7714, batch_loss: 0.1375, loss: 0.3161 ||:  16%|#6        | 2073/12754 [24:19<1:57:28,  1.52it/s]
2025-05-27 20:30:28,477 - INFO - tqdm - accuracy: 0.8803, precision: 0.8830, recall: 0.8803, f1-score: 0.8814, diff_precision: 0.9284, diff_recall: 0.9093, diff_f1-score: 0.9187, same_precision: 0.7509, same_recall: 0.7959, same_f1-score: 0.7727, batch_loss: 0.0943, loss: 0.3142 ||:  16%|#6        | 2088/12754 [24:30<2:04:22,  1.43it/s]
2025-05-27 20:30:38,926 - INFO - tqdm - accuracy: 0.8807, precision: 0.8834, recall: 0.8807, f1-score: 0.8818, diff_precision: 0.9288, diff_recall: 0.9095, diff_f1-score: 0.9190, same_precision: 0.7513, same_recall: 0.7967, same_f1-score: 0.7733, batch_loss: 0.0024, loss: 0.3131 ||:  16%|#6        | 2102/12754 [24:40<2:05:26,  1.42it/s]
2025-05-27 20:30:49,375 - INFO - tqdm - accuracy: 0.8811, precision: 0.8837, recall: 0.8811, f1-score: 0.8822, diff_precision: 0.9288, diff_recall: 0.9102, diff_f1-score: 0.9194, same_precision: 0.7522, same_recall: 0.7962, same_f1-score: 0.7736, batch_loss: 0.0076, loss: 0.3125 ||:  17%|#6        | 2117/12754 [24:51<2:16:04,  1.30it/s]
2025-05-27 20:30:59,670 - INFO - tqdm - accuracy: 0.8815, precision: 0.8841, recall: 0.8815, f1-score: 0.8825, diff_precision: 0.9291, diff_recall: 0.9104, diff_f1-score: 0.9196, same_precision: 0.7526, same_recall: 0.7970, same_f1-score: 0.7742, batch_loss: 0.1872, loss: 0.3116 ||:  17%|#6        | 2130/12754 [25:01<2:18:05,  1.28it/s]
2025-05-27 20:31:10,289 - INFO - tqdm - accuracy: 0.8821, precision: 0.8847, recall: 0.8821, f1-score: 0.8832, diff_precision: 0.9296, diff_recall: 0.9111, diff_f1-score: 0.9202, same_precision: 0.7529, same_recall: 0.7970, same_f1-score: 0.7743, batch_loss: 0.0009, loss: 0.3099 ||:  17%|#6        | 2144/12754 [25:11<2:05:19,  1.41it/s]
2025-05-27 20:31:20,601 - INFO - tqdm - accuracy: 0.8828, precision: 0.8854, recall: 0.8828, f1-score: 0.8839, diff_precision: 0.9299, diff_recall: 0.9117, diff_f1-score: 0.9207, same_precision: 0.7540, same_recall: 0.7975, same_f1-score: 0.7752, batch_loss: 0.0740, loss: 0.3082 ||:  17%|#6        | 2159/12754 [25:22<2:00:51,  1.46it/s]
2025-05-27 20:31:30,736 - INFO - tqdm - accuracy: 0.8835, precision: 0.8861, recall: 0.8835, f1-score: 0.8846, diff_precision: 0.9305, diff_recall: 0.9125, diff_f1-score: 0.9214, same_precision: 0.7540, same_recall: 0.7975, same_f1-score: 0.7752, batch_loss: 0.0010, loss: 0.3063 ||:  17%|#7        | 2173/12754 [25:32<1:59:41,  1.47it/s]
2025-05-27 20:31:41,457 - INFO - tqdm - accuracy: 0.8842, precision: 0.8868, recall: 0.8842, f1-score: 0.8853, diff_precision: 0.9310, diff_recall: 0.9131, diff_f1-score: 0.9220, same_precision: 0.7547, same_recall: 0.7979, same_f1-score: 0.7757, batch_loss: 0.0021, loss: 0.3049 ||:  17%|#7        | 2188/12754 [25:43<2:07:19,  1.38it/s]
2025-05-27 20:31:51,666 - INFO - tqdm - accuracy: 0.8847, precision: 0.8871, recall: 0.8847, f1-score: 0.8857, diff_precision: 0.9311, diff_recall: 0.9136, diff_f1-score: 0.9223, same_precision: 0.7561, same_recall: 0.7984, same_f1-score: 0.7766, batch_loss: 0.0067, loss: 0.3039 ||:  17%|#7        | 2202/12754 [25:53<2:05:02,  1.41it/s]
2025-05-27 20:32:01,878 - INFO - tqdm - accuracy: 0.8854, precision: 0.8878, recall: 0.8854, f1-score: 0.8864, diff_precision: 0.9316, diff_recall: 0.9142, diff_f1-score: 0.9228, same_precision: 0.7567, same_recall: 0.7991, same_f1-score: 0.7773, batch_loss: 0.0244, loss: 0.3022 ||:  17%|#7        | 2216/12754 [26:03<2:02:35,  1.43it/s]
2025-05-27 20:32:11,974 - INFO - tqdm - accuracy: 0.8860, precision: 0.8883, recall: 0.8860, f1-score: 0.8869, diff_precision: 0.9318, diff_recall: 0.9147, diff_f1-score: 0.9232, same_precision: 0.7582, same_recall: 0.7999, same_f1-score: 0.7785, batch_loss: 0.0654, loss: 0.3006 ||:  17%|#7        | 2231/12754 [26:13<1:46:25,  1.65it/s]
2025-05-27 20:32:22,319 - INFO - tqdm - accuracy: 0.8866, precision: 0.8889, recall: 0.8866, f1-score: 0.8876, diff_precision: 0.9322, diff_recall: 0.9153, diff_f1-score: 0.9237, same_precision: 0.7593, same_recall: 0.8004, same_f1-score: 0.7793, batch_loss: 0.0112, loss: 0.2991 ||:  18%|#7        | 2246/12754 [26:24<1:57:03,  1.50it/s]
2025-05-27 20:32:32,636 - INFO - tqdm - accuracy: 0.8871, precision: 0.8894, recall: 0.8871, f1-score: 0.8880, diff_precision: 0.9326, diff_recall: 0.9157, diff_f1-score: 0.9241, same_precision: 0.7595, same_recall: 0.8009, same_f1-score: 0.7796, batch_loss: 0.0335, loss: 0.2977 ||:  18%|#7        | 2261/12754 [26:34<1:54:09,  1.53it/s]
2025-05-27 20:32:43,109 - INFO - tqdm - accuracy: 0.8876, precision: 0.8899, recall: 0.8876, f1-score: 0.8886, diff_precision: 0.9328, diff_recall: 0.9162, diff_f1-score: 0.9244, same_precision: 0.7612, same_recall: 0.8017, same_f1-score: 0.7809, batch_loss: 0.0025, loss: 0.2963 ||:  18%|#7        | 2277/12754 [26:44<1:58:15,  1.48it/s]
2025-05-27 20:32:53,124 - INFO - tqdm - accuracy: 0.8881, precision: 0.8903, recall: 0.8881, f1-score: 0.8890, diff_precision: 0.9329, diff_recall: 0.9166, diff_f1-score: 0.9247, same_precision: 0.7624, same_recall: 0.8024, same_f1-score: 0.7818, batch_loss: 0.0160, loss: 0.2954 ||:  18%|#7        | 2292/12754 [26:54<2:00:23,  1.45it/s]
2025-05-27 20:33:03,803 - INFO - tqdm - accuracy: 0.8885, precision: 0.8908, recall: 0.8885, f1-score: 0.8895, diff_precision: 0.9332, diff_recall: 0.9170, diff_f1-score: 0.9250, same_precision: 0.7635, same_recall: 0.8032, same_f1-score: 0.7828, batch_loss: 0.0936, loss: 0.2942 ||:  18%|#8        | 2307/12754 [27:05<1:59:50,  1.45it/s]
2025-05-27 20:33:14,078 - INFO - tqdm - accuracy: 0.8890, precision: 0.8912, recall: 0.8890, f1-score: 0.8899, diff_precision: 0.9333, diff_recall: 0.9175, diff_f1-score: 0.9253, same_precision: 0.7648, same_recall: 0.8038, same_f1-score: 0.7838, batch_loss: 0.3469, loss: 0.2930 ||:  18%|#8        | 2321/12754 [27:15<2:13:08,  1.31it/s]
2025-05-27 20:33:24,410 - INFO - tqdm - accuracy: 0.8896, precision: 0.8917, recall: 0.8896, f1-score: 0.8905, diff_precision: 0.9335, diff_recall: 0.9179, diff_f1-score: 0.9256, same_precision: 0.7669, same_recall: 0.8052, same_f1-score: 0.7855, batch_loss: 0.1045, loss: 0.2915 ||:  18%|#8        | 2337/12754 [27:26<2:02:33,  1.42it/s]
2025-05-27 20:33:34,586 - INFO - tqdm - accuracy: 0.8902, precision: 0.8923, recall: 0.8902, f1-score: 0.8911, diff_precision: 0.9339, diff_recall: 0.9183, diff_f1-score: 0.9260, same_precision: 0.7682, same_recall: 0.8065, same_f1-score: 0.7869, batch_loss: 0.0032, loss: 0.2900 ||:  18%|#8        | 2351/12754 [27:36<1:58:26,  1.46it/s]
2025-05-27 20:33:44,762 - INFO - tqdm - accuracy: 0.8906, precision: 0.8926, recall: 0.8906, f1-score: 0.8914, diff_precision: 0.9340, diff_recall: 0.9186, diff_f1-score: 0.9263, same_precision: 0.7698, same_recall: 0.8075, same_f1-score: 0.7882, batch_loss: 0.0022, loss: 0.2888 ||:  19%|#8        | 2364/12754 [27:46<2:12:12,  1.31it/s]
2025-05-27 20:33:55,294 - INFO - tqdm - accuracy: 0.8911, precision: 0.8931, recall: 0.8911, f1-score: 0.8920, diff_precision: 0.9344, diff_recall: 0.9191, diff_f1-score: 0.9267, same_precision: 0.7703, same_recall: 0.8077, same_f1-score: 0.7886, batch_loss: 0.0018, loss: 0.2874 ||:  19%|#8        | 2379/12754 [27:57<1:48:47,  1.59it/s]
2025-05-27 20:34:05,668 - INFO - tqdm - accuracy: 0.8917, precision: 0.8936, recall: 0.8917, f1-score: 0.8925, diff_precision: 0.9347, diff_recall: 0.9196, diff_f1-score: 0.9271, same_precision: 0.7711, same_recall: 0.8083, same_f1-score: 0.7893, batch_loss: 0.0037, loss: 0.2862 ||:  19%|#8        | 2394/12754 [28:07<2:09:10,  1.34it/s]
2025-05-27 20:34:16,192 - INFO - tqdm - accuracy: 0.8923, precision: 0.8943, recall: 0.8923, f1-score: 0.8931, diff_precision: 0.9352, diff_recall: 0.9201, diff_f1-score: 0.9276, same_precision: 0.7718, same_recall: 0.8090, same_f1-score: 0.7899, batch_loss: 0.0037, loss: 0.2845 ||:  19%|#8        | 2409/12754 [28:17<1:53:03,  1.53it/s]
2025-05-27 20:34:26,312 - INFO - tqdm - accuracy: 0.8927, precision: 0.8946, recall: 0.8927, f1-score: 0.8935, diff_precision: 0.9352, diff_recall: 0.9205, diff_f1-score: 0.9278, same_precision: 0.7741, same_recall: 0.8102, same_f1-score: 0.7918, batch_loss: 0.0136, loss: 0.2836 ||:  19%|#9        | 2424/12754 [28:28<1:45:45,  1.63it/s]
2025-05-27 20:34:36,493 - INFO - tqdm - accuracy: 0.8933, precision: 0.8952, recall: 0.8933, f1-score: 0.8941, diff_precision: 0.9356, diff_recall: 0.9209, diff_f1-score: 0.9282, same_precision: 0.7745, same_recall: 0.8108, same_f1-score: 0.7922, batch_loss: 0.0039, loss: 0.2822 ||:  19%|#9        | 2439/12754 [28:38<1:54:03,  1.51it/s]
2025-05-27 20:34:47,413 - INFO - tqdm - accuracy: 0.8938, precision: 0.8957, recall: 0.8938, f1-score: 0.8946, diff_precision: 0.9360, diff_recall: 0.9214, diff_f1-score: 0.9286, same_precision: 0.7754, same_recall: 0.8115, same_f1-score: 0.7930, batch_loss: 0.0005, loss: 0.2806 ||:  19%|#9        | 2454/12754 [28:49<2:13:06,  1.29it/s]
2025-05-27 20:34:57,943 - INFO - tqdm - accuracy: 0.8941, precision: 0.8959, recall: 0.8941, f1-score: 0.8949, diff_precision: 0.9360, diff_recall: 0.9219, diff_f1-score: 0.9289, same_precision: 0.7762, same_recall: 0.8112, same_f1-score: 0.7933, batch_loss: 0.0020, loss: 0.2805 ||:  19%|#9        | 2468/12754 [28:59<2:05:34,  1.37it/s]
2025-05-27 20:35:08,125 - INFO - tqdm - accuracy: 0.8947, precision: 0.8965, recall: 0.8947, f1-score: 0.8955, diff_precision: 0.9363, diff_recall: 0.9223, diff_f1-score: 0.9293, same_precision: 0.7772, same_recall: 0.8121, same_f1-score: 0.7943, batch_loss: 0.0283, loss: 0.2790 ||:  19%|#9        | 2482/12754 [29:09<1:52:15,  1.53it/s]
2025-05-27 20:35:18,330 - INFO - tqdm - accuracy: 0.8953, precision: 0.8971, recall: 0.8953, f1-score: 0.8961, diff_precision: 0.9367, diff_recall: 0.9227, diff_f1-score: 0.9296, same_precision: 0.7788, same_recall: 0.8136, same_f1-score: 0.7958, batch_loss: 0.0285, loss: 0.2776 ||:  20%|#9        | 2497/12754 [29:20<1:54:50,  1.49it/s]
2025-05-27 20:35:28,446 - INFO - tqdm - accuracy: 0.8956, precision: 0.8973, recall: 0.8956, f1-score: 0.8963, diff_precision: 0.9366, diff_recall: 0.9230, diff_f1-score: 0.9298, same_precision: 0.7800, same_recall: 0.8138, same_f1-score: 0.7965, batch_loss: 0.0648, loss: 0.2767 ||:  20%|#9        | 2512/12754 [29:30<1:49:44,  1.56it/s]
2025-05-27 20:35:38,714 - INFO - tqdm - accuracy: 0.8955, precision: 0.8972, recall: 0.8955, f1-score: 0.8962, diff_precision: 0.9367, diff_recall: 0.9228, diff_f1-score: 0.9297, same_precision: 0.7795, same_recall: 0.8139, same_f1-score: 0.7963, batch_loss: 0.0078, loss: 0.2776 ||:  20%|#9        | 2526/12754 [29:40<1:57:38,  1.45it/s]
2025-05-27 20:35:49,238 - INFO - tqdm - accuracy: 0.8960, precision: 0.8977, recall: 0.8960, f1-score: 0.8967, diff_precision: 0.9369, diff_recall: 0.9233, diff_f1-score: 0.9301, same_precision: 0.7803, same_recall: 0.8143, same_f1-score: 0.7969, batch_loss: 0.0138, loss: 0.2765 ||:  20%|#9        | 2541/12754 [29:50<2:03:36,  1.38it/s]
2025-05-27 20:35:59,728 - INFO - tqdm - accuracy: 0.8963, precision: 0.8979, recall: 0.8963, f1-score: 0.8970, diff_precision: 0.9370, diff_recall: 0.9237, diff_f1-score: 0.9303, same_precision: 0.7814, same_recall: 0.8144, same_f1-score: 0.7975, batch_loss: 0.0678, loss: 0.2757 ||:  20%|##        | 2556/12754 [30:01<2:12:33,  1.28it/s]
2025-05-27 20:36:10,136 - INFO - tqdm - accuracy: 0.8967, precision: 0.8983, recall: 0.8967, f1-score: 0.8974, diff_precision: 0.9371, diff_recall: 0.9241, diff_f1-score: 0.9305, same_precision: 0.7826, same_recall: 0.8151, same_f1-score: 0.7985, batch_loss: 0.3040, loss: 0.2750 ||:  20%|##        | 2572/12754 [30:11<1:50:07,  1.54it/s]
2025-05-27 20:36:20,168 - INFO - tqdm - accuracy: 0.8972, precision: 0.8988, recall: 0.8972, f1-score: 0.8979, diff_precision: 0.9374, diff_recall: 0.9245, diff_f1-score: 0.9309, same_precision: 0.7831, same_recall: 0.8153, same_f1-score: 0.7989, batch_loss: 0.0884, loss: 0.2737 ||:  20%|##        | 2587/12754 [30:21<1:56:45,  1.45it/s]
2025-05-27 20:36:30,235 - INFO - tqdm - accuracy: 0.8976, precision: 0.8991, recall: 0.8976, f1-score: 0.8983, diff_precision: 0.9376, diff_recall: 0.9250, diff_f1-score: 0.9312, same_precision: 0.7840, same_recall: 0.8156, same_f1-score: 0.7995, batch_loss: 0.0126, loss: 0.2728 ||:  20%|##        | 2601/12754 [30:31<2:03:46,  1.37it/s]
2025-05-27 20:36:40,776 - INFO - tqdm - accuracy: 0.8981, precision: 0.8997, recall: 0.8981, f1-score: 0.8988, diff_precision: 0.9379, diff_recall: 0.9255, diff_f1-score: 0.9317, same_precision: 0.7846, same_recall: 0.8159, same_f1-score: 0.7999, batch_loss: 0.0071, loss: 0.2715 ||:  21%|##        | 2616/12754 [30:42<2:00:12,  1.41it/s]
2025-05-27 20:36:51,246 - INFO - tqdm - accuracy: 0.8985, precision: 0.8999, recall: 0.8985, f1-score: 0.8991, diff_precision: 0.9378, diff_recall: 0.9258, diff_f1-score: 0.9318, same_precision: 0.7868, same_recall: 0.8170, same_f1-score: 0.8017, batch_loss: 0.0368, loss: 0.2708 ||:  21%|##        | 2632/12754 [30:52<2:05:41,  1.34it/s]
2025-05-27 20:37:02,027 - INFO - tqdm - accuracy: 0.8985, precision: 0.9000, recall: 0.8985, f1-score: 0.8991, diff_precision: 0.9380, diff_recall: 0.9254, diff_f1-score: 0.9317, same_precision: 0.7869, same_recall: 0.8183, same_f1-score: 0.8023, batch_loss: 0.0009, loss: 0.2705 ||:  21%|##        | 2649/12754 [31:03<1:59:23,  1.41it/s]
2025-05-27 20:37:12,086 - INFO - tqdm - accuracy: 0.8988, precision: 0.9002, recall: 0.8988, f1-score: 0.8994, diff_precision: 0.9381, diff_recall: 0.9258, diff_f1-score: 0.9319, same_precision: 0.7877, same_recall: 0.8184, same_f1-score: 0.8027, batch_loss: 0.0004, loss: 0.2699 ||:  21%|##        | 2662/12754 [31:13<2:06:29,  1.33it/s]
2025-05-27 20:37:22,702 - INFO - tqdm - accuracy: 0.8991, precision: 0.9006, recall: 0.8991, f1-score: 0.8998, diff_precision: 0.9382, diff_recall: 0.9262, diff_f1-score: 0.9322, same_precision: 0.7887, same_recall: 0.8187, same_f1-score: 0.8034, batch_loss: 0.6329, loss: 0.2689 ||:  21%|##        | 2677/12754 [31:24<2:02:49,  1.37it/s]
2025-05-27 20:37:33,113 - INFO - tqdm - accuracy: 0.8995, precision: 0.9009, recall: 0.8995, f1-score: 0.9001, diff_precision: 0.9384, diff_recall: 0.9264, diff_f1-score: 0.9324, same_precision: 0.7897, same_recall: 0.8198, same_f1-score: 0.8045, batch_loss: 0.9270, loss: 0.2680 ||:  21%|##1       | 2692/12754 [31:34<1:53:06,  1.48it/s]
2025-05-27 20:37:43,132 - INFO - tqdm - accuracy: 0.9000, precision: 0.9014, recall: 0.9000, f1-score: 0.9006, diff_precision: 0.9387, diff_recall: 0.9268, diff_f1-score: 0.9327, same_precision: 0.7906, same_recall: 0.8203, same_f1-score: 0.8052, batch_loss: 0.0199, loss: 0.2667 ||:  21%|##1       | 2707/12754 [31:44<1:35:14,  1.76it/s]
2025-05-27 20:37:53,404 - INFO - tqdm - accuracy: 0.9005, precision: 0.9018, recall: 0.9005, f1-score: 0.9011, diff_precision: 0.9391, diff_recall: 0.9273, diff_f1-score: 0.9331, same_precision: 0.7908, same_recall: 0.8205, same_f1-score: 0.8054, batch_loss: 0.0027, loss: 0.2655 ||:  21%|##1       | 2721/12754 [31:55<2:02:52,  1.36it/s]
2025-05-27 20:38:03,964 - INFO - tqdm - accuracy: 0.9009, precision: 0.9023, recall: 0.9009, f1-score: 0.9015, diff_precision: 0.9393, diff_recall: 0.9277, diff_f1-score: 0.9335, same_precision: 0.7915, same_recall: 0.8209, same_f1-score: 0.8059, batch_loss: 0.0004, loss: 0.2645 ||:  21%|##1       | 2737/12754 [32:05<1:43:01,  1.62it/s]
2025-05-27 20:38:14,403 - INFO - tqdm - accuracy: 0.9014, precision: 0.9027, recall: 0.9014, f1-score: 0.9020, diff_precision: 0.9395, diff_recall: 0.9281, diff_f1-score: 0.9338, same_precision: 0.7929, same_recall: 0.8216, same_f1-score: 0.8070, batch_loss: 0.0017, loss: 0.2635 ||:  22%|##1       | 2754/12754 [32:16<1:43:48,  1.61it/s]
2025-05-27 20:38:25,225 - INFO - tqdm - accuracy: 0.9019, precision: 0.9032, recall: 0.9019, f1-score: 0.9025, diff_precision: 0.9398, diff_recall: 0.9285, diff_f1-score: 0.9341, same_precision: 0.7940, same_recall: 0.8225, same_f1-score: 0.8080, batch_loss: 0.0083, loss: 0.2622 ||:  22%|##1       | 2770/12754 [32:26<2:10:58,  1.27it/s]
2025-05-27 20:38:35,875 - INFO - tqdm - accuracy: 0.9023, precision: 0.9036, recall: 0.9023, f1-score: 0.9029, diff_precision: 0.9400, diff_recall: 0.9288, diff_f1-score: 0.9344, same_precision: 0.7955, same_recall: 0.8236, same_f1-score: 0.8093, batch_loss: 0.0297, loss: 0.2613 ||:  22%|##1       | 2786/12754 [32:37<1:49:22,  1.52it/s]
2025-05-27 20:38:45,937 - INFO - tqdm - accuracy: 0.9027, precision: 0.9040, recall: 0.9027, f1-score: 0.9033, diff_precision: 0.9401, diff_recall: 0.9292, diff_f1-score: 0.9346, same_precision: 0.7965, same_recall: 0.8241, same_f1-score: 0.8101, batch_loss: 0.0051, loss: 0.2604 ||:  22%|##1       | 2801/12754 [32:47<1:47:55,  1.54it/s]
2025-05-27 20:38:56,242 - INFO - tqdm - accuracy: 0.9032, precision: 0.9045, recall: 0.9032, f1-score: 0.9038, diff_precision: 0.9406, diff_recall: 0.9296, diff_f1-score: 0.9350, same_precision: 0.7966, same_recall: 0.8244, same_f1-score: 0.8102, batch_loss: 0.0010, loss: 0.2591 ||:  22%|##2       | 2817/12754 [32:57<1:48:06,  1.53it/s]
2025-05-27 20:39:06,399 - INFO - tqdm - accuracy: 0.9035, precision: 0.9048, recall: 0.9035, f1-score: 0.9041, diff_precision: 0.9407, diff_recall: 0.9300, diff_f1-score: 0.9353, same_precision: 0.7968, same_recall: 0.8242, same_f1-score: 0.8102, batch_loss: 0.0012, loss: 0.2586 ||:  22%|##2       | 2829/12754 [33:08<2:27:05,  1.12it/s]
2025-05-27 20:39:16,423 - INFO - tqdm - accuracy: 0.9039, precision: 0.9051, recall: 0.9039, f1-score: 0.9044, diff_precision: 0.9409, diff_recall: 0.9304, diff_f1-score: 0.9356, same_precision: 0.7972, same_recall: 0.8242, same_f1-score: 0.8105, batch_loss: 0.0405, loss: 0.2577 ||:  22%|##2       | 2843/12754 [33:18<2:01:03,  1.36it/s]
2025-05-27 20:39:26,562 - INFO - tqdm - accuracy: 0.9042, precision: 0.9054, recall: 0.9042, f1-score: 0.9048, diff_precision: 0.9411, diff_recall: 0.9306, diff_f1-score: 0.9358, same_precision: 0.7984, same_recall: 0.8252, same_f1-score: 0.8116, batch_loss: 0.0877, loss: 0.2568 ||:  22%|##2       | 2857/12754 [33:28<2:01:49,  1.35it/s]
2025-05-27 20:39:36,846 - INFO - tqdm - accuracy: 0.9048, precision: 0.9059, recall: 0.9048, f1-score: 0.9053, diff_precision: 0.9414, diff_recall: 0.9310, diff_f1-score: 0.9362, same_precision: 0.7992, same_recall: 0.8258, same_f1-score: 0.8123, batch_loss: 0.0825, loss: 0.2554 ||:  23%|##2       | 2873/12754 [33:38<1:27:20,  1.89it/s]
2025-05-27 20:39:47,193 - INFO - tqdm - accuracy: 0.9050, precision: 0.9062, recall: 0.9050, f1-score: 0.9056, diff_precision: 0.9416, diff_recall: 0.9313, diff_f1-score: 0.9364, same_precision: 0.7998, same_recall: 0.8260, same_f1-score: 0.8127, batch_loss: 0.0043, loss: 0.2545 ||:  23%|##2       | 2887/12754 [33:48<2:07:07,  1.29it/s]
2025-05-27 20:39:57,559 - INFO - tqdm - accuracy: 0.9056, precision: 0.9067, recall: 0.9056, f1-score: 0.9061, diff_precision: 0.9419, diff_recall: 0.9317, diff_f1-score: 0.9368, same_precision: 0.8003, same_recall: 0.8265, same_f1-score: 0.8132, batch_loss: 0.0006, loss: 0.2531 ||:  23%|##2       | 2903/12754 [33:59<1:46:58,  1.53it/s]
2025-05-27 20:40:07,921 - INFO - tqdm - accuracy: 0.9060, precision: 0.9071, recall: 0.9060, f1-score: 0.9065, diff_precision: 0.9421, diff_recall: 0.9321, diff_f1-score: 0.9371, same_precision: 0.8014, same_recall: 0.8272, same_f1-score: 0.8141, batch_loss: 0.0019, loss: 0.2520 ||:  23%|##2       | 2917/12754 [34:09<2:15:50,  1.21it/s]
2025-05-27 20:40:18,861 - INFO - tqdm - accuracy: 0.9063, precision: 0.9074, recall: 0.9063, f1-score: 0.9068, diff_precision: 0.9422, diff_recall: 0.9322, diff_f1-score: 0.9372, same_precision: 0.8033, same_recall: 0.8286, same_f1-score: 0.8157, batch_loss: 0.1710, loss: 0.2514 ||:  23%|##2       | 2932/12754 [34:20<2:05:03,  1.31it/s]
2025-05-27 20:40:28,967 - INFO - tqdm - accuracy: 0.9067, precision: 0.9078, recall: 0.9067, f1-score: 0.9072, diff_precision: 0.9423, diff_recall: 0.9325, diff_f1-score: 0.9374, same_precision: 0.8048, same_recall: 0.8299, same_f1-score: 0.8172, batch_loss: 0.0057, loss: 0.2503 ||:  23%|##3       | 2946/12754 [34:30<2:04:02,  1.32it/s]
2025-05-27 20:40:39,221 - INFO - tqdm - accuracy: 0.9071, precision: 0.9081, recall: 0.9071, f1-score: 0.9075, diff_precision: 0.9426, diff_recall: 0.9328, diff_f1-score: 0.9377, same_precision: 0.8051, same_recall: 0.8302, same_f1-score: 0.8175, batch_loss: 0.2124, loss: 0.2493 ||:  23%|##3       | 2960/12754 [34:40<2:02:35,  1.33it/s]
2025-05-27 20:40:49,850 - INFO - tqdm - accuracy: 0.9074, precision: 0.9085, recall: 0.9074, f1-score: 0.9079, diff_precision: 0.9427, diff_recall: 0.9331, diff_f1-score: 0.9379, same_precision: 0.8063, same_recall: 0.8310, same_f1-score: 0.8185, batch_loss: 0.0127, loss: 0.2484 ||:  23%|##3       | 2975/12754 [34:51<2:02:48,  1.33it/s]
2025-05-27 20:41:00,387 - INFO - tqdm - accuracy: 0.9077, precision: 0.9087, recall: 0.9077, f1-score: 0.9081, diff_precision: 0.9428, diff_recall: 0.9333, diff_f1-score: 0.9380, same_precision: 0.8075, same_recall: 0.8317, same_f1-score: 0.8194, batch_loss: 0.0107, loss: 0.2480 ||:  23%|##3       | 2990/12754 [35:02<1:48:45,  1.50it/s]
2025-05-27 20:41:10,490 - INFO - tqdm - accuracy: 0.9080, precision: 0.9090, recall: 0.9080, f1-score: 0.9084, diff_precision: 0.9431, diff_recall: 0.9335, diff_f1-score: 0.9383, same_precision: 0.8073, same_recall: 0.8318, same_f1-score: 0.8194, batch_loss: 0.0004, loss: 0.2472 ||:  24%|##3       | 3005/12754 [35:12<1:41:04,  1.61it/s]
2025-05-27 20:41:20,973 - INFO - tqdm - accuracy: 0.9082, precision: 0.9091, recall: 0.9082, f1-score: 0.9086, diff_precision: 0.9429, diff_recall: 0.9337, diff_f1-score: 0.9383, same_precision: 0.8088, same_recall: 0.8322, same_f1-score: 0.8204, batch_loss: 0.0026, loss: 0.2472 ||:  24%|##3       | 3020/12754 [35:22<1:59:09,  1.36it/s]
2025-05-27 20:41:31,450 - INFO - tqdm - accuracy: 0.9086, precision: 0.9095, recall: 0.9086, f1-score: 0.9090, diff_precision: 0.9432, diff_recall: 0.9341, diff_f1-score: 0.9386, same_precision: 0.8096, same_recall: 0.8329, same_f1-score: 0.8210, batch_loss: 0.0002, loss: 0.2463 ||:  24%|##3       | 3034/12754 [35:33<2:08:26,  1.26it/s]
2025-05-27 20:41:41,696 - INFO - tqdm - accuracy: 0.9091, precision: 0.9100, recall: 0.9091, f1-score: 0.9095, diff_precision: 0.9434, diff_recall: 0.9343, diff_f1-score: 0.9389, same_precision: 0.8112, same_recall: 0.8343, same_f1-score: 0.8226, batch_loss: 0.0033, loss: 0.2450 ||:  24%|##3       | 3051/12754 [35:43<1:36:55,  1.67it/s]
2025-05-27 20:41:52,003 - INFO - tqdm - accuracy: 0.9094, precision: 0.9104, recall: 0.9094, f1-score: 0.9098, diff_precision: 0.9436, diff_recall: 0.9346, diff_f1-score: 0.9391, same_precision: 0.8123, same_recall: 0.8351, same_f1-score: 0.8236, batch_loss: 0.3979, loss: 0.2440 ||:  24%|##4       | 3066/12754 [35:53<1:53:29,  1.42it/s]
2025-05-27 20:42:02,305 - INFO - tqdm - accuracy: 0.9098, precision: 0.9108, recall: 0.9098, f1-score: 0.9103, diff_precision: 0.9439, diff_recall: 0.9350, diff_f1-score: 0.9394, same_precision: 0.8125, same_recall: 0.8353, same_f1-score: 0.8238, batch_loss: 0.0013, loss: 0.2430 ||:  24%|##4       | 3080/12754 [36:04<1:51:29,  1.45it/s]
2025-05-27 20:42:12,645 - INFO - tqdm - accuracy: 0.9102, precision: 0.9111, recall: 0.9102, f1-score: 0.9106, diff_precision: 0.9441, diff_recall: 0.9352, diff_f1-score: 0.9396, same_precision: 0.8137, same_recall: 0.8362, same_f1-score: 0.8248, batch_loss: 0.0389, loss: 0.2420 ||:  24%|##4       | 3094/12754 [36:14<2:15:29,  1.19it/s]
2025-05-27 20:42:23,423 - INFO - tqdm - accuracy: 0.9106, precision: 0.9115, recall: 0.9106, f1-score: 0.9110, diff_precision: 0.9444, diff_recall: 0.9355, diff_f1-score: 0.9399, same_precision: 0.8142, same_recall: 0.8368, same_f1-score: 0.8253, batch_loss: 0.0009, loss: 0.2409 ||:  24%|##4       | 3110/12754 [36:25<2:05:03,  1.29it/s]
2025-05-27 20:42:33,860 - INFO - tqdm - accuracy: 0.9110, precision: 0.9119, recall: 0.9110, f1-score: 0.9114, diff_precision: 0.9447, diff_recall: 0.9359, diff_f1-score: 0.9402, same_precision: 0.8147, same_recall: 0.8372, same_f1-score: 0.8258, batch_loss: 0.0145, loss: 0.2398 ||:  24%|##4       | 3124/12754 [36:35<1:55:14,  1.39it/s]
2025-05-27 20:42:44,031 - INFO - tqdm - accuracy: 0.9114, precision: 0.9123, recall: 0.9114, f1-score: 0.9118, diff_precision: 0.9450, diff_recall: 0.9362, diff_f1-score: 0.9406, same_precision: 0.8149, same_recall: 0.8374, same_f1-score: 0.8260, batch_loss: 0.0007, loss: 0.2387 ||:  25%|##4       | 3138/12754 [36:45<1:54:45,  1.40it/s]
2025-05-27 20:42:54,288 - INFO - tqdm - accuracy: 0.9118, precision: 0.9127, recall: 0.9118, f1-score: 0.9122, diff_precision: 0.9452, diff_recall: 0.9365, diff_f1-score: 0.9408, same_precision: 0.8156, same_recall: 0.8378, same_f1-score: 0.8265, batch_loss: 0.0490, loss: 0.2380 ||:  25%|##4       | 3153/12754 [36:55<1:38:28,  1.62it/s]
2025-05-27 20:43:04,868 - INFO - tqdm - accuracy: 0.9121, precision: 0.9130, recall: 0.9121, f1-score: 0.9125, diff_precision: 0.9453, diff_recall: 0.9368, diff_f1-score: 0.9410, same_precision: 0.8168, same_recall: 0.8387, same_f1-score: 0.8276, batch_loss: 0.0568, loss: 0.2371 ||:  25%|##4       | 3169/12754 [37:06<1:56:08,  1.38it/s]
2025-05-27 20:43:14,896 - INFO - tqdm - accuracy: 0.9125, precision: 0.9134, recall: 0.9125, f1-score: 0.9129, diff_precision: 0.9455, diff_recall: 0.9371, diff_f1-score: 0.9413, same_precision: 0.8180, same_recall: 0.8397, same_f1-score: 0.8287, batch_loss: 0.0048, loss: 0.2361 ||:  25%|##4       | 3183/12754 [37:16<2:08:36,  1.24it/s]
2025-05-27 20:43:25,135 - INFO - tqdm - accuracy: 0.9128, precision: 0.9136, recall: 0.9128, f1-score: 0.9131, diff_precision: 0.9458, diff_recall: 0.9372, diff_f1-score: 0.9415, same_precision: 0.8179, same_recall: 0.8400, same_f1-score: 0.8288, batch_loss: 0.0001, loss: 0.2353 ||:  25%|##5       | 3198/12754 [37:26<1:42:13,  1.56it/s]
2025-05-27 20:43:35,175 - INFO - tqdm - accuracy: 0.9130, precision: 0.9138, recall: 0.9130, f1-score: 0.9134, diff_precision: 0.9458, diff_recall: 0.9374, diff_f1-score: 0.9416, same_precision: 0.8191, same_recall: 0.8406, same_f1-score: 0.8297, batch_loss: 0.0000, loss: 0.2347 ||:  25%|##5       | 3213/12754 [37:36<1:59:30,  1.33it/s]
2025-05-27 20:43:45,682 - INFO - tqdm - accuracy: 0.9132, precision: 0.9140, recall: 0.9132, f1-score: 0.9136, diff_precision: 0.9459, diff_recall: 0.9376, diff_f1-score: 0.9417, same_precision: 0.8196, same_recall: 0.8409, same_f1-score: 0.8301, batch_loss: 0.0422, loss: 0.2343 ||:  25%|##5       | 3228/12754 [37:47<1:48:50,  1.46it/s]
2025-05-27 20:43:56,164 - INFO - tqdm - accuracy: 0.9136, precision: 0.9144, recall: 0.9136, f1-score: 0.9139, diff_precision: 0.9461, diff_recall: 0.9378, diff_f1-score: 0.9419, same_precision: 0.8206, same_recall: 0.8418, same_f1-score: 0.8311, batch_loss: 0.0005, loss: 0.2334 ||:  25%|##5       | 3243/12754 [37:57<1:37:35,  1.62it/s]
2025-05-27 20:44:06,791 - INFO - tqdm - accuracy: 0.9138, precision: 0.9146, recall: 0.9138, f1-score: 0.9142, diff_precision: 0.9463, diff_recall: 0.9380, diff_f1-score: 0.9421, same_precision: 0.8207, same_recall: 0.8420, same_f1-score: 0.8312, batch_loss: 0.0003, loss: 0.2325 ||:  26%|##5       | 3258/12754 [38:08<1:48:30,  1.46it/s]
2025-05-27 20:44:16,855 - INFO - tqdm - accuracy: 0.9142, precision: 0.9150, recall: 0.9142, f1-score: 0.9146, diff_precision: 0.9466, diff_recall: 0.9383, diff_f1-score: 0.9424, same_precision: 0.8211, same_recall: 0.8423, same_f1-score: 0.8316, batch_loss: 0.0002, loss: 0.2315 ||:  26%|##5       | 3273/12754 [38:18<1:38:05,  1.61it/s]
2025-05-27 20:44:26,914 - INFO - tqdm - accuracy: 0.9146, precision: 0.9154, recall: 0.9146, f1-score: 0.9149, diff_precision: 0.9468, diff_recall: 0.9386, diff_f1-score: 0.9427, same_precision: 0.8221, same_recall: 0.8433, same_f1-score: 0.8326, batch_loss: 0.0431, loss: 0.2305 ||:  26%|##5       | 3287/12754 [38:28<2:02:53,  1.28it/s]
2025-05-27 20:44:37,550 - INFO - tqdm - accuracy: 0.9149, precision: 0.9157, recall: 0.9149, f1-score: 0.9153, diff_precision: 0.9470, diff_recall: 0.9388, diff_f1-score: 0.9429, same_precision: 0.8232, same_recall: 0.8442, same_f1-score: 0.8335, batch_loss: 0.0018, loss: 0.2296 ||:  26%|##5       | 3302/12754 [38:39<1:59:46,  1.32it/s]
2025-05-27 20:44:48,146 - INFO - tqdm - accuracy: 0.9149, precision: 0.9157, recall: 0.9149, f1-score: 0.9153, diff_precision: 0.9470, diff_recall: 0.9387, diff_f1-score: 0.9428, same_precision: 0.8234, same_recall: 0.8448, same_f1-score: 0.8340, batch_loss: 2.6905, loss: 0.2299 ||:  26%|##6       | 3318/12754 [38:49<1:38:30,  1.60it/s]
2025-05-27 20:44:58,184 - INFO - tqdm - accuracy: 0.9152, precision: 0.9160, recall: 0.9152, f1-score: 0.9155, diff_precision: 0.9471, diff_recall: 0.9389, diff_f1-score: 0.9430, same_precision: 0.8241, same_recall: 0.8451, same_f1-score: 0.8345, batch_loss: 0.0003, loss: 0.2294 ||:  26%|##6       | 3332/12754 [38:59<2:03:19,  1.27it/s]
2025-05-27 20:45:08,266 - INFO - tqdm - accuracy: 0.9155, precision: 0.9162, recall: 0.9155, f1-score: 0.9158, diff_precision: 0.9472, diff_recall: 0.9392, diff_f1-score: 0.9432, same_precision: 0.8247, same_recall: 0.8454, same_f1-score: 0.8349, batch_loss: 0.3630, loss: 0.2288 ||:  26%|##6       | 3346/12754 [39:09<1:58:20,  1.32it/s]
2025-05-27 20:45:18,293 - INFO - tqdm - accuracy: 0.9156, precision: 0.9164, recall: 0.9156, f1-score: 0.9160, diff_precision: 0.9473, diff_recall: 0.9393, diff_f1-score: 0.9433, same_precision: 0.8252, same_recall: 0.8457, same_f1-score: 0.8353, batch_loss: 0.0027, loss: 0.2284 ||:  26%|##6       | 3360/12754 [39:20<1:46:20,  1.47it/s]
2025-05-27 20:45:29,231 - INFO - tqdm - accuracy: 0.9160, precision: 0.9168, recall: 0.9160, f1-score: 0.9163, diff_precision: 0.9475, diff_recall: 0.9396, diff_f1-score: 0.9435, same_precision: 0.8259, same_recall: 0.8463, same_f1-score: 0.8360, batch_loss: 0.0012, loss: 0.2277 ||:  26%|##6       | 3376/12754 [39:30<2:06:37,  1.23it/s]
2025-05-27 20:45:39,877 - INFO - tqdm - accuracy: 0.9163, precision: 0.9171, recall: 0.9163, f1-score: 0.9167, diff_precision: 0.9477, diff_recall: 0.9399, diff_f1-score: 0.9438, same_precision: 0.8263, same_recall: 0.8465, same_f1-score: 0.8363, batch_loss: 0.0016, loss: 0.2268 ||:  27%|##6       | 3391/12754 [39:41<1:47:07,  1.46it/s]
2025-05-27 20:45:50,681 - INFO - tqdm - accuracy: 0.9165, precision: 0.9172, recall: 0.9165, f1-score: 0.9168, diff_precision: 0.9478, diff_recall: 0.9402, diff_f1-score: 0.9440, same_precision: 0.8266, same_recall: 0.8460, same_f1-score: 0.8362, batch_loss: 0.0842, loss: 0.2267 ||:  27%|##6       | 3407/12754 [39:52<1:52:07,  1.39it/s]
2025-05-27 20:46:00,937 - INFO - tqdm - accuracy: 0.9167, precision: 0.9174, recall: 0.9167, f1-score: 0.9170, diff_precision: 0.9477, diff_recall: 0.9404, diff_f1-score: 0.9440, same_precision: 0.8275, same_recall: 0.8464, same_f1-score: 0.8368, batch_loss: 1.1256, loss: 0.2264 ||:  27%|##6       | 3422/12754 [40:02<1:50:30,  1.41it/s]
2025-05-27 20:46:11,151 - INFO - tqdm - accuracy: 0.9168, precision: 0.9175, recall: 0.9168, f1-score: 0.9171, diff_precision: 0.9478, diff_recall: 0.9405, diff_f1-score: 0.9442, same_precision: 0.8279, same_recall: 0.8467, same_f1-score: 0.8372, batch_loss: 0.1571, loss: 0.2260 ||:  27%|##6       | 3437/12754 [40:12<1:44:01,  1.49it/s]
2025-05-27 20:46:21,224 - INFO - tqdm - accuracy: 0.9171, precision: 0.9178, recall: 0.9171, f1-score: 0.9174, diff_precision: 0.9479, diff_recall: 0.9408, diff_f1-score: 0.9443, same_precision: 0.8286, same_recall: 0.8471, same_f1-score: 0.8378, batch_loss: 0.0370, loss: 0.2254 ||:  27%|##7       | 3451/12754 [40:22<1:58:24,  1.31it/s]
2025-05-27 20:46:31,245 - INFO - tqdm - accuracy: 0.9174, precision: 0.9181, recall: 0.9174, f1-score: 0.9177, diff_precision: 0.9481, diff_recall: 0.9410, diff_f1-score: 0.9445, same_precision: 0.8293, same_recall: 0.8477, same_f1-score: 0.8384, batch_loss: 0.0011, loss: 0.2245 ||:  27%|##7       | 3465/12754 [40:32<1:43:57,  1.49it/s]
2025-05-27 20:46:41,343 - INFO - tqdm - accuracy: 0.9177, precision: 0.9184, recall: 0.9177, f1-score: 0.9180, diff_precision: 0.9483, diff_recall: 0.9412, diff_f1-score: 0.9448, same_precision: 0.8298, same_recall: 0.8483, same_f1-score: 0.8389, batch_loss: 0.0001, loss: 0.2236 ||:  27%|##7       | 3480/12754 [40:43<1:38:24,  1.57it/s]
2025-05-27 20:46:51,772 - INFO - tqdm - accuracy: 0.9179, precision: 0.9186, recall: 0.9179, f1-score: 0.9182, diff_precision: 0.9484, diff_recall: 0.9414, diff_f1-score: 0.9449, same_precision: 0.8303, same_recall: 0.8483, same_f1-score: 0.8392, batch_loss: 0.5834, loss: 0.2235 ||:  27%|##7       | 3494/12754 [40:53<1:39:11,  1.56it/s]
2025-05-27 20:47:02,231 - INFO - tqdm - accuracy: 0.9182, precision: 0.9188, recall: 0.9182, f1-score: 0.9185, diff_precision: 0.9485, diff_recall: 0.9417, diff_f1-score: 0.9451, same_precision: 0.8308, same_recall: 0.8486, same_f1-score: 0.8396, batch_loss: 0.0017, loss: 0.2228 ||:  27%|##7       | 3507/12754 [41:03<1:52:03,  1.38it/s]
2025-05-27 20:47:12,849 - INFO - tqdm - accuracy: 0.9185, precision: 0.9191, recall: 0.9185, f1-score: 0.9188, diff_precision: 0.9487, diff_recall: 0.9419, diff_f1-score: 0.9453, same_precision: 0.8313, same_recall: 0.8490, same_f1-score: 0.8401, batch_loss: 0.0861, loss: 0.2220 ||:  28%|##7       | 3521/12754 [41:14<2:14:38,  1.14it/s]
2025-05-27 20:47:23,197 - INFO - tqdm - accuracy: 0.9188, precision: 0.9194, recall: 0.9188, f1-score: 0.9191, diff_precision: 0.9489, diff_recall: 0.9422, diff_f1-score: 0.9456, same_precision: 0.8315, same_recall: 0.8491, same_f1-score: 0.8402, batch_loss: 0.0010, loss: 0.2212 ||:  28%|##7       | 3536/12754 [41:24<1:46:26,  1.44it/s]
2025-05-27 20:47:33,748 - INFO - tqdm - accuracy: 0.9191, precision: 0.9197, recall: 0.9191, f1-score: 0.9194, diff_precision: 0.9492, diff_recall: 0.9425, diff_f1-score: 0.9458, same_precision: 0.8318, same_recall: 0.8493, same_f1-score: 0.8404, batch_loss: 0.0164, loss: 0.2203 ||:  28%|##7       | 3552/12754 [41:35<1:39:59,  1.53it/s]
2025-05-27 20:47:44,275 - INFO - tqdm - accuracy: 0.9194, precision: 0.9200, recall: 0.9194, f1-score: 0.9197, diff_precision: 0.9494, diff_recall: 0.9427, diff_f1-score: 0.9460, same_precision: 0.8322, same_recall: 0.8496, same_f1-score: 0.8408, batch_loss: 0.0905, loss: 0.2196 ||:  28%|##7       | 3568/12754 [41:45<1:41:09,  1.51it/s]
2025-05-27 20:47:54,539 - INFO - tqdm - accuracy: 0.9197, precision: 0.9203, recall: 0.9197, f1-score: 0.9199, diff_precision: 0.9495, diff_recall: 0.9429, diff_f1-score: 0.9462, same_precision: 0.8334, same_recall: 0.8505, same_f1-score: 0.8419, batch_loss: 0.0005, loss: 0.2188 ||:  28%|##8       | 3584/12754 [41:56<1:36:24,  1.59it/s]
2025-05-27 20:48:04,936 - INFO - tqdm - accuracy: 0.9200, precision: 0.9206, recall: 0.9200, f1-score: 0.9203, diff_precision: 0.9497, diff_recall: 0.9432, diff_f1-score: 0.9464, same_precision: 0.8336, same_recall: 0.8507, same_f1-score: 0.8420, batch_loss: 0.0006, loss: 0.2179 ||:  28%|##8       | 3599/12754 [42:06<1:46:15,  1.44it/s]
2025-05-27 20:48:15,512 - INFO - tqdm - accuracy: 0.9203, precision: 0.9209, recall: 0.9203, f1-score: 0.9206, diff_precision: 0.9499, diff_recall: 0.9435, diff_f1-score: 0.9466, same_precision: 0.8343, same_recall: 0.8511, same_f1-score: 0.8426, batch_loss: 0.0000, loss: 0.2172 ||:  28%|##8       | 3615/12754 [42:17<1:47:23,  1.42it/s]
2025-05-27 20:48:25,898 - INFO - tqdm - accuracy: 0.9206, precision: 0.9211, recall: 0.9206, f1-score: 0.9208, diff_precision: 0.9500, diff_recall: 0.9437, diff_f1-score: 0.9468, same_precision: 0.8349, same_recall: 0.8516, same_f1-score: 0.8432, batch_loss: 0.8100, loss: 0.2166 ||:  28%|##8       | 3629/12754 [42:27<1:52:44,  1.35it/s]
2025-05-27 20:48:36,438 - INFO - tqdm - accuracy: 0.9206, precision: 0.9212, recall: 0.9206, f1-score: 0.9209, diff_precision: 0.9501, diff_recall: 0.9435, diff_f1-score: 0.9468, same_precision: 0.8350, same_recall: 0.8523, same_f1-score: 0.8436, batch_loss: 3.0453, loss: 0.2166 ||:  29%|##8       | 3644/12754 [42:38<2:00:58,  1.26it/s]
2025-05-27 20:48:46,948 - INFO - tqdm - accuracy: 0.9210, precision: 0.9215, recall: 0.9210, f1-score: 0.9212, diff_precision: 0.9504, diff_recall: 0.9439, diff_f1-score: 0.9471, same_precision: 0.8352, same_recall: 0.8523, same_f1-score: 0.8437, batch_loss: 0.0001, loss: 0.2158 ||:  29%|##8       | 3660/12754 [42:48<1:35:43,  1.58it/s]
2025-05-27 20:48:57,089 - INFO - tqdm - accuracy: 0.9210, precision: 0.9215, recall: 0.9210, f1-score: 0.9212, diff_precision: 0.9503, diff_recall: 0.9438, diff_f1-score: 0.9471, same_precision: 0.8356, same_recall: 0.8526, same_f1-score: 0.8440, batch_loss: 0.0005, loss: 0.2160 ||:  29%|##8       | 3676/12754 [42:58<1:42:13,  1.48it/s]
2025-05-27 20:49:07,525 - INFO - tqdm - accuracy: 0.9211, precision: 0.9216, recall: 0.9211, f1-score: 0.9213, diff_precision: 0.9503, diff_recall: 0.9441, diff_f1-score: 0.9472, same_precision: 0.8360, same_recall: 0.8523, same_f1-score: 0.8441, batch_loss: 0.0228, loss: 0.2159 ||:  29%|##8       | 3691/12754 [43:09<1:52:28,  1.34it/s]
2025-05-27 20:49:18,310 - INFO - tqdm - accuracy: 0.9211, precision: 0.9217, recall: 0.9211, f1-score: 0.9214, diff_precision: 0.9502, diff_recall: 0.9443, diff_f1-score: 0.9472, same_precision: 0.8366, same_recall: 0.8522, same_f1-score: 0.8443, batch_loss: 0.6612, loss: 0.2158 ||:  29%|##9       | 3707/12754 [43:20<1:45:12,  1.43it/s]
2025-05-27 20:49:28,705 - INFO - tqdm - accuracy: 0.9213, precision: 0.9218, recall: 0.9213, f1-score: 0.9215, diff_precision: 0.9503, diff_recall: 0.9443, diff_f1-score: 0.9473, same_precision: 0.8369, same_recall: 0.8525, same_f1-score: 0.8446, batch_loss: 0.0407, loss: 0.2157 ||:  29%|##9       | 3721/12754 [43:30<1:55:44,  1.30it/s]
2025-05-27 20:49:39,042 - INFO - tqdm - accuracy: 0.9214, precision: 0.9219, recall: 0.9214, f1-score: 0.9216, diff_precision: 0.9502, diff_recall: 0.9445, diff_f1-score: 0.9474, same_precision: 0.8374, same_recall: 0.8525, same_f1-score: 0.8449, batch_loss: 0.0257, loss: 0.2158 ||:  29%|##9       | 3735/12754 [43:40<1:46:04,  1.42it/s]
2025-05-27 20:49:49,591 - INFO - tqdm - accuracy: 0.9217, precision: 0.9222, recall: 0.9217, f1-score: 0.9219, diff_precision: 0.9504, diff_recall: 0.9447, diff_f1-score: 0.9475, same_precision: 0.8384, same_recall: 0.8534, same_f1-score: 0.8458, batch_loss: 0.1008, loss: 0.2150 ||:  29%|##9       | 3751/12754 [43:51<1:51:54,  1.34it/s]
2025-05-27 20:49:59,621 - INFO - tqdm - accuracy: 0.9220, precision: 0.9225, recall: 0.9220, f1-score: 0.9222, diff_precision: 0.9506, diff_recall: 0.9449, diff_f1-score: 0.9477, same_precision: 0.8387, same_recall: 0.8536, same_f1-score: 0.8461, batch_loss: 0.0020, loss: 0.2144 ||:  30%|##9       | 3764/12754 [44:01<1:48:20,  1.38it/s]
2025-05-27 20:50:09,990 - INFO - tqdm - accuracy: 0.9222, precision: 0.9227, recall: 0.9222, f1-score: 0.9224, diff_precision: 0.9507, diff_recall: 0.9451, diff_f1-score: 0.9479, same_precision: 0.8390, same_recall: 0.8536, same_f1-score: 0.8463, batch_loss: 0.0454, loss: 0.2138 ||:  30%|##9       | 3778/12754 [44:11<1:53:53,  1.31it/s]
2025-05-27 20:50:20,361 - INFO - tqdm - accuracy: 0.9224, precision: 0.9229, recall: 0.9224, f1-score: 0.9227, diff_precision: 0.9508, diff_recall: 0.9453, diff_f1-score: 0.9481, same_precision: 0.8397, same_recall: 0.8543, same_f1-score: 0.8469, batch_loss: 0.0010, loss: 0.2130 ||:  30%|##9       | 3794/12754 [44:22<1:32:01,  1.62it/s]
2025-05-27 20:50:30,539 - INFO - tqdm - accuracy: 0.9227, precision: 0.9232, recall: 0.9227, f1-score: 0.9229, diff_precision: 0.9510, diff_recall: 0.9455, diff_f1-score: 0.9482, same_precision: 0.8402, same_recall: 0.8545, same_f1-score: 0.8473, batch_loss: 0.0020, loss: 0.2123 ||:  30%|##9       | 3808/12754 [44:32<1:48:16,  1.38it/s]
2025-05-27 20:50:41,133 - INFO - tqdm - accuracy: 0.9229, precision: 0.9233, recall: 0.9229, f1-score: 0.9231, diff_precision: 0.9511, diff_recall: 0.9456, diff_f1-score: 0.9484, same_precision: 0.8406, same_recall: 0.8549, same_f1-score: 0.8477, batch_loss: 0.0033, loss: 0.2118 ||:  30%|##9       | 3823/12754 [44:42<1:44:00,  1.43it/s]
2025-05-27 20:50:51,399 - INFO - tqdm - accuracy: 0.9231, precision: 0.9236, recall: 0.9231, f1-score: 0.9233, diff_precision: 0.9513, diff_recall: 0.9459, diff_f1-score: 0.9486, same_precision: 0.8408, same_recall: 0.8550, same_f1-score: 0.8478, batch_loss: 0.9352, loss: 0.2113 ||:  30%|###       | 3837/12754 [44:53<1:43:10,  1.44it/s]
2025-05-27 20:50:59,089 - INFO - root - Training interrupted by the user, and no best model has been saved. No model archive created.
